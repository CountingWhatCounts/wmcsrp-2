{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/run-results/v6.json", "dbt_version": "1.9.2", "generated_at": "2025-02-13T17:19:03.956779Z", "invocation_id": "9a80dcbd-f7a1-405f-b2a3-ce71843d02eb", "env": {}}, "results": [{"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.709562Z", "completed_at": "2025-02-13T17:19:03.743218Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.747147Z", "completed_at": "2025-02-13T17:19:03.747166Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.04217219352722168, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__ace_levelling_up_for_culture_places", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='ace_levelling_up_for_culture_places')\n\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_csv(io.BytesIO(data))\n    df.columns = [x.lower() for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__ace_levelling_up_for_culture_places\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__ace_levelling_up_for_culture_places\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__ace_levelling_up_for_culture_places\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.735639Z", "completed_at": "2025-02-13T17:19:03.743808Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.748034Z", "completed_at": "2025-02-13T17:19:03.748043Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.04189252853393555, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__ace_npo_funding", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='ace_npo_funding')\n\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_excel(io.BytesIO(data), sheet_name='data', engine=\"openpyxl\")\n    df.columns = [x.lower().replace(' ','_').replace('\\n', '_').replace('/','_').replace('(','_').replace(')','_') for x in df.columns]\n    df = df.rename(columns={\n        \"2018-22_average_annual_funding__figure_accurate_at_april_2018_\": \"average_annual_funding_2018_22\",\n        \"2022_23_annual_funding__extension_year_\": \"annual_funding__extension_year_2022_23\",\n        \"2023-26_annual_funding__offered_4_nov_2022_\": \"annual_funding__offered_4_nov_2022_2023_26\",\n    })\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__ace_npo_funding\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__ace_npo_funding\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__ace_npo_funding\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.739675Z", "completed_at": "2025-02-13T17:19:03.748751Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.751180Z", "completed_at": "2025-02-13T17:19:03.751190Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.04334378242492676, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__ace_priority_places", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='ace_priority_places')\n\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_csv(io.BytesIO(data))\n    df.columns = [x.lower() for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__ace_priority_places\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__ace_priority_places\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__ace_priority_places\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.744266Z", "completed_at": "2025-02-13T17:19:03.750021Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.752500Z", "completed_at": "2025-02-13T17:19:03.752512Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.04364466667175293, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__ace_project_grants", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='ace_project_grants')\n\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_excel(io.BytesIO(data), sheet_name='Project Grants Awards', engine=\"openpyxl\")\n    df.columns = df.iloc[1, :]\n    df = df.iloc[2:, :]\n    df.columns = [x.lower().replace(' ','_') for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__ace_project_grants\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__ace_project_grants\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__ace_project_grants\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.756459Z", "completed_at": "2025-02-13T17:19:03.767846Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.771730Z", "completed_at": "2025-02-13T17:19:03.771742Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.01988983154296875, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__census", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef get_geography_from_filename(filename: str) -> str:\n    return filename.split('.')[0].split('-')[2]\n\n\ndef process_age_data(age_data: pd.DataFrame) -> pd.DataFrame:\n    column_groups = {\n        'Age: Age 16-19': ['Age: Aged 16 to 19 years; measures: Value'],\n        'Age: Age 20-24': ['Age: Aged 20 to 24 years; measures: Value'],\n        'Age: Age 25-29': [\n            'Age: Aged 25 years; measures: Value',\n            'Age: Aged 26 years; measures: Value',\n            'Age: Aged 27 years; measures: Value',\n            'Age: Aged 28 years; measures: Value',\n            'Age: Aged 29 years; measures: Value'\n        ],\n        'Age: Age 30-34': [\n            'Age: Aged 30 years; measures: Value',\n            'Age: Aged 31 years; measures: Value',\n            'Age: Aged 32 years; measures: Value',\n            'Age: Aged 33 years; measures: Value',\n            'Age: Aged 34 years; measures: Value'\n        ],\n        'Age: Age 35-39': [\n            'Age: Aged 35 years; measures: Value',\n            'Age: Aged 36 years; measures: Value',\n            'Age: Aged 37 years; measures: Value',\n            'Age: Aged 38 years; measures: Value',\n            'Age: Aged 39 years; measures: Value'\n        ],\n        'Age: Age 40-44': [\n            'Age: Aged 40 years; measures: Value',\n            'Age: Aged 41 years; measures: Value',\n            'Age: Aged 42 years; measures: Value',\n            'Age: Aged 43 years; measures: Value',\n            'Age: Aged 44 years; measures: Value'\n        ],\n        'Age: Age 45-49': [\n            'Age: Aged 45 years; measures: Value',\n            'Age: Aged 46 years; measures: Value',\n            'Age: Aged 47 years; measures: Value',\n            'Age: Aged 48 years; measures: Value',\n            'Age: Aged 49 years; measures: Value'\n        ],\n        'Age: Age 50-54': [\n            'Age: Aged 50 years; measures: Value',\n            'Age: Aged 51 years; measures: Value',\n            'Age: Aged 52 years; measures: Value',\n            'Age: Aged 53 years; measures: Value',\n            'Age: Aged 54 years; measures: Value'\n        ],\n        'Age: Age 55-59': [\n            'Age: Aged 55 years; measures: Value',\n            'Age: Aged 56 years; measures: Value',\n            'Age: Aged 57 years; measures: Value',\n            'Age: Aged 58 years; measures: Value',\n            'Age: Aged 59 years; measures: Value'\n        ],\n        'Age: Age 60-64': [\n            'Age: Aged 60 years; measures: Value',\n            'Age: Aged 61 years; measures: Value',\n            'Age: Aged 62 years; measures: Value',\n            'Age: Aged 63 years; measures: Value',\n            'Age: Aged 64 years; measures: Value'\n        ],\n        'Age: Age 65-69': [\n            'Age: Aged 65 years; measures: Value',\n            'Age: Aged 66 years; measures: Value',\n            'Age: Aged 67 years; measures: Value',\n            'Age: Aged 68 years; measures: Value',\n            'Age: Aged 69 years; measures: Value'\n        ],\n        'Age: Age 70-74': [\n            'Age: Aged 70 years; measures: Value',\n            'Age: Aged 71 years; measures: Value',\n            'Age: Aged 72 years; measures: Value',\n            'Age: Aged 73 years; measures: Value',\n            'Age: Aged 74 years; measures: Value'\n        ],\n        'Age: Age 75-79': [\n            'Age: Aged 75 years; measures: Value',\n            'Age: Aged 76 years; measures: Value',\n            'Age: Aged 77 years; measures: Value',\n            'Age: Aged 78 years; measures: Value',\n            'Age: Aged 79 years; measures: Value'\n        ],\n        'Age: Age 80-84': [\n            'Age: Aged 80 years; measures: Value',\n            'Age: Aged 81 years; measures: Value',\n            'Age: Aged 82 years; measures: Value',\n            'Age: Aged 83 years; measures: Value',\n            'Age: Aged 84 years; measures: Value'\n        ],\n        'Age: Age 85 and over': ['Age: Aged 85 years and over; measures: Value']\n        \n    }\n\n    df = age_data.copy()\n    for new_col, existing_columns in column_groups.items():\n        df[new_col] = df[existing_columns].sum(axis=1)\n\n    final_columns = ['date','geography','geography code','Age: Total; measures: Value'] + list(column_groups.keys())\n    df = df[final_columns]\n\n    return df\n\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='census')\n\n    frames = []\n    for blob in blobs:\n        if not blob.name.endswith('.csv'):\n            continue\n\n        geography = get_geography_from_filename(blob.name)    \n        if 'msoa' not in blob.name: # Only process MSOA data\n            continue\n            \n        try:\n            data = blob.download_as_bytes()\n            df = pd.read_csv(io.BytesIO(data))\n        except pd.errors.EmptyDataError as e:\n            continue\n\n        # If age data then preprocess\n        if 'ts007' in blob.name:\n            df = process_age_data(df)\n\n        total_column = [col for col in df.columns if 'Total' in col or 'All persons' in col][0] # Get total column\n        data_content = total_column.split(':')[0] # Get data content from column\n        value_columns = [col for col in df.columns if col not in ['date', 'geography', 'geography code', total_column]] # Get value columns\n\n        df_totals = df[['date', 'geography', 'geography code', total_column]].drop_duplicates()\n        df_values = df[['geography code'] + value_columns]\n        df_values = df_values.melt(\n            id_vars='geography code',\n            var_name='measure',\n            value_name='count'\n        )\n\n        df = df_totals.merge(df_values, how='left', on='geography code')\n        df = df.rename(columns={total_column: 'n', 'date': 'year'})\n\n        df['content'] = data_content\n        df['geography'] = geography\n        df = df[df['measure']!=total_column]\n        df['measure'] = df['measure'].apply(lambda x: (':').join(x.split(':')[1:]))\n        frames.append(df)\n\n    df = pd.concat(frames)\n    df.columns = [x.lower().replace(' ','_') for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__census\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__census\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__census\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.759850Z", "completed_at": "2025-02-13T17:19:03.768345Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.772600Z", "completed_at": "2025-02-13T17:19:03.772610Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.019487619400024414, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__cultural_infrastructure", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='services')\n\n    frames = []\n    for blob in blobs:\n        data = blob.download_as_bytes()\n        df = pd.read_csv(io.BytesIO(data))\n        df.columns = [x.lower().replace(' ', '_').replace('(', '').replace(')', '').replace(':', '_') for x in df.columns]\n        frames.append(df)\n    df = pd.concat(frames)\n    df = df.drop('amount_awarded', axis=1)\n    df['postcode'] = df['postcode'].apply(lambda x: x.replace(' ', ''))\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__cultural_infrastructure\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__cultural_infrastructure\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__cultural_infrastructure\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.765067Z", "completed_at": "2025-02-13T17:19:03.773311Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.775693Z", "completed_at": "2025-02-13T17:19:03.775705Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.0198514461517334, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__economic", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport numpy as np\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef filter_columns(df: pd.DataFrame):\n    column_indices = [0]\n    i = 0\n    while i < len(df.columns):\n        if i + 3 < len(df.columns):\n            column_indices.extend([i + 3, i + 4])\n        i += 4\n\n    df = df.iloc[:, column_indices]\n    return df\n\n\n\ndef model(dbt, session):\n    \n    pd.set_option('future.no_silent_downcasting', True)\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='economic')\n\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n    df = pd.read_csv(io.BytesIO(data))\n\n    df.columns = df.loc[5,:]\n    df = df.loc[7:, :]\n    df = filter_columns(df)\n\n    new_columns = []\n    new_columns.append(df.columns[0])\n    i = 1\n    while i < len(df.columns):\n        if i + 1 < len(df.columns):\n            new_columns.append(df.columns[i] + ' - Value')\n            new_columns.append(df.columns[i] + ' - Margin of Error')\n        i += 2\n    df.columns = new_columns\n\n    df = df.replace(['#', '-', '!', '*', '~'], np.nan)\n    df = df.dropna(how='all')\n\n    local_authority_col = 'local authority: district / unitary (as of April 2021)'\n\n    # Identify value and margin columns\n    value_columns = [col for col in df.columns if 'Value' in col]\n\n    # Create a mapping from 'Value' columns to their corresponding 'Margin of Error' columns\n    value_to_margin_map = {\n        value_col: value_col.replace('Value', 'Margin of Error')\n        for value_col in value_columns\n    }\n\n    # Prepare an empty DataFrame to store the melted data\n    melted_df = pd.DataFrame()\n\n    # Melt the DataFrame for each pair of value and margin columns\n    for value_col, margin_col in value_to_margin_map.items():\n        temp_df = df[[local_authority_col, value_col, margin_col]].copy()\n        temp_df.columns = ['local authority', 'value', 'margin of error']\n        temp_df['measure'] = value_col.replace(' - Value', '')\n        melted_df = pd.concat([melted_df, temp_df], ignore_index=True)\n\n    melted_df = melted_df.reset_index(names='ID')\n    melted_df = melted_df[['ID', 'local authority', 'measure', 'value', 'margin of error']]\n    melted_df['value'] = melted_df['value'].apply(lambda x: float(x) / 100)\n    melted_df['margin of error'] = melted_df['margin of error'].apply(lambda x: float(x) / 100)\n    melted_df.columns = [x.lower().replace(' ','_') for x in melted_df.columns]\n\n    return melted_df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__economic\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__economic\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__economic\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.768851Z", "completed_at": "2025-02-13T17:19:03.774616Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.776947Z", "completed_at": "2025-02-13T17:19:03.776956Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.017725229263305664, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__grant360", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='grant360')\n\n    frames = []\n    for blob in blobs:\n        data = blob.download_as_bytes()\n        df = pd.read_csv(io.BytesIO(data))\n        df.columns = [x.lower().replace(' ', '_').replace('(', '').replace(')', '').replace(':', '_') for x in df.columns]\n        frames.append(df)\n    df = pd.concat(frames)\n    \n    df['award_date'] = df['award_date'].astype(str)\n    df['award_date'] = df['award_date'].apply(lambda x: x.replace('/', '-'))\n    df['award_date'] = df['award_date'].apply(lambda x: pd.to_datetime(x).strftime('%Y-%m-%d'))\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__grant360\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__grant360\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__grant360\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.780855Z", "completed_at": "2025-02-13T17:19:03.788481Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.795154Z", "completed_at": "2025-02-13T17:19:03.795166Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.018866539001464844, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__indices_of_deprivation", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='indices_of_deprivation')\n    \n    for blob in blobs:\n        if blob.name.endswith('.csv'):\n            data = blob.download_as_bytes()\n    df = pd.read_csv(io.BytesIO(data))\n    df.columns = [x.lower().replace(' ', '_') for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__indices_of_deprivation\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__indices_of_deprivation\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__indices_of_deprivation\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.784478Z", "completed_at": "2025-02-13T17:19:03.788994Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.795956Z", "completed_at": "2025-02-13T17:19:03.795964Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.018378496170043945, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__msoa_mapping", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='msoa_mapping')\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_csv(io.BytesIO(data))\n    df.columns = [x.lower() for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__msoa_mapping\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__msoa_mapping\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__msoa_mapping\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.789493Z", "completed_at": "2025-02-13T17:19:03.796932Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.799022Z", "completed_at": "2025-02-13T17:19:03.799027Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.018799543380737305, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__msoa_population", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='msoa_population')\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_excel(io.BytesIO(data), sheet_name='Mid-2021 MSOA 2021', engine='openpyxl')\n    df.columns = df.iloc[2, :]\n    df = df.iloc[3:, :]\n    df = df[['MSOA 2021 Code', 'Total']]\n    df.columns = [x.lower().replace(' ', '_') for x in df.columns]\n    df = df.rename(columns={'msoa_2021_code': 'msoa21cd', 'total': 'population'})\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__msoa_population\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__msoa_population\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__msoa_population\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.792365Z", "completed_at": "2025-02-13T17:19:03.797931Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.800413Z", "completed_at": "2025-02-13T17:19:03.800420Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.016570329666137695, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__postcode_mapping", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nimport numpy as np\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='postcode_mapping')\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_csv(io.BytesIO(data))\n    df = df.replace(r'^\\s*$', np.nan, regex=True)\n    df.columns = [x.lower() for x in df.columns]\n    df['pcd_no_space'] = df['pcd2'].apply(lambda x: x.replace(' ', ''))\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__postcode_mapping\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__postcode_mapping\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__postcode_mapping\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.804301Z", "completed_at": "2025-02-13T17:19:03.811863Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.817572Z", "completed_at": "2025-02-13T17:19:03.817582Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.017786264419555664, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__rural_urban_classification", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nimport numpy as np\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='rural_urban_classification')\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_csv(io.BytesIO(data))\n    df.columns = [x.lower() for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__rural_urban_classification\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__rural_urban_classification\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__rural_urban_classification\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.807896Z", "completed_at": "2025-02-13T17:19:03.814758Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.818449Z", "completed_at": "2025-02-13T17:19:03.818456Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.017414093017578125, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__wellbeing", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nimport numpy as np\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    pd.set_option('future.no_silent_downcasting', True)\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='wellbeing')\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    sheets = {\n        '1 Life satisfaction means': 11,\n        '4 Worthwhile means': 11,\n        '7 Happiness means': 11,\n        '10 Anxiety means': 12\n    }\n\n    sheet_frames = []\n\n    for sheet, columns_row in sheets.items():\n\n        df = pd.read_excel(io.BytesIO(data), sheet_name=sheet, engine='openpyxl')\n        df.columns = df.iloc[columns_row,:]\n        df = df.iloc[columns_row+1:,1:]\n\n        df = df.replace('[cv1]', '<5%')\n        df = df.replace('[cv2]', '5-10%')\n        df = df.replace('[cv3]', '10-20%')\n        df = df.replace('[cv4]', '>20%')\n        df = df.replace('[u]', np.nan)\n        df = df.replace('[x]', np.nan)\n\n        index_column = 'Area Codes'\n\n        melted_df = pd.DataFrame()\n        i = 1\n        while i < len(df.columns):\n            value_column = df.columns[i]\n            error_column = df.columns[i+1]\n            temp_df = df[[index_column, value_column, error_column]].copy()\n            temp_df['date'] = value_column\n            temp_df.columns = ['area codes', 'value', 'margin of error', 'date']\n            melted_df = pd.concat([melted_df, temp_df], ignore_index=True)\n            i += 2\n\n        melted_df['wellbeing_factor'] = sheet\n        sheet_frames.append(melted_df)\n    df = pd.concat(sheet_frames)\n\n    df['wellbeing_factor'] = df['wellbeing_factor'].apply(lambda x: ' '.join(x.split(' ')[1:]))\n    df['value'] = df['value'].astype(float)\n    df = df.reset_index(names='ID')\n    df.columns = [x.lower().replace(' ','_') for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__wellbeing\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__wellbeing\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__wellbeing\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.812409Z", "completed_at": "2025-02-13T17:19:03.819261Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.821198Z", "completed_at": "2025-02-13T17:19:03.821205Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.017497539520263672, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.ace_levelling_up_for_culture_places", "compiled": true, "compiled_code": "select\n    *\nfrom\n    \"WMCSRP2\".\"md_raw\".\"raw__ace_levelling_up_for_culture_places\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"Arts Council England Levelling Up for Culture Places\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.815245Z", "completed_at": "2025-02-13T17:19:03.820305Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.822925Z", "completed_at": "2025-02-13T17:19:03.822931Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.015651702880859375, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.ace_priority_places", "compiled": true, "compiled_code": "select\n    *\nfrom\n    \"WMCSRP2\".\"md_raw\".\"raw__ace_priority_places\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"Arts Council England Priority Places\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.827989Z", "completed_at": "2025-02-13T17:19:03.832736Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.833219Z", "completed_at": "2025-02-13T17:19:03.833225Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.009565114974975586, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__rural_urban_classification", "compiled": true, "compiled_code": "with\n\nruc as (\n    select * from \"WMCSRP2\".\"md_raw\".\"raw__rural_urban_classification\"\n),\n\nmsoa_mapping as (\n    select * from \"WMCSRP2\".\"md_raw\".\"raw__msoa_mapping\"\n),\n\ncombined as (\n    select\n        ruc.msoa11cd,\n        ruc.msoa11nm,\n        ruc11cd,\n        ruc11\n    from ruc\n    left join msoa_mapping\n    on ruc.msoa11cd = msoa_mapping.msoa11cd\n)\n\nselect * from combined", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__rural_urban_classification\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.825365Z", "completed_at": "2025-02-13T17:19:03.834142Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.834659Z", "completed_at": "2025-02-13T17:19:03.834664Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.012361526489257812, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__area_codes", "compiled": true, "compiled_code": "with\n\ntarget_areas as (\n    select\n        case\n            when lad22nm in (\n                'Birmingham',\n                'Coventry',\n                'Dudley',\n                'Sandwell',\n                'Solihull',\n                'Walsall',\n                'Wolverhampton'\n            ) then 'WMCA Constituent Member'\n            when lad22nm in (\n                'Cannock Chase',\n                'North Warwickshire',\n                'Nuneaton and Bedworth',\n                'Redditch',\n                'Rugby',\n                'Shropshire',\n                'Stratford-on-Avon',\n                'Tamworth',\n                'Telford and Wrekin',\n                'Warwick'\n            ) then 'WMCA Non-Constituent Member'\n            when lad22nm in (\n                'Bromsgrove',\n                'East Staffordshire',\n                'Herefordshire, County of',\n                'Lichfield',\n                'Malvern Hills',\n                'Newcastle-under-Lyme',\n                'South Staffordshire',\n                'Stafford',\n                'Staffordshire Moorlands',\n                'Stoke-on-Trent',\n                'Worcester',\n                'Wychavon',\n                'Wyre Forest'\n            ) then 'West Midlands Non-WMCA'\n            else 'Ignore'\n        end as area,\n        lad22cd,\n        lad22nm,\n        msoa21cd,\n        msoa21nm\n    from\n        \"WMCSRP2\".\"md_raw\".\"raw__msoa_mapping\"\n)\n\nselect * from target_areas where area != 'Ignore'", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.837527Z", "completed_at": "2025-02-13T17:19:03.842342Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.846993Z", "completed_at": "2025-02-13T17:19:03.847001Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.011008262634277344, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.rural_urban_classification", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__rural_urban_classification\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"Rural Urban Classification\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.843839Z", "completed_at": "2025-02-13T17:19:03.851512Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.856268Z", "completed_at": "2025-02-13T17:19:03.856276Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.014986991882324219, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__ace_npo_funding_aggregated", "compiled": true, "compiled_code": "with npo_funding as (\n    select * from \"WMCSRP2\".\"md_raw\".\"raw__ace_npo_funding\"\n),\n\n\naggregated as (\n    select\n        sum(annual_funding__extension_year_2022_23) as sum_annual_funding_extension_year,\n        sum(annual_funding__offered_4_nov_2022_2023_26) as sum_annual_funding_2023_2026,\n        sum(average_annual_funding_2018_22) sum_average_annual_funding_2018_2022,\n        local_authority\n    from\n        npo_funding\n    group by\n        local_authority\n),\n\nmsoa_mapping as (\n    select\n        lad22cd,\n        lad22nm\n    from\n        \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n),\n\n\ncombined as (\n    select\n        distinct lad22cd,\n        lad22nm,\n        case\n            when sum_annual_funding_extension_year is null then 0\n            else sum_annual_funding_extension_year\n        end as sum_annual_funding_extension_year,\n        case\n            when sum_annual_funding_2023_2026 is null then 0\n            else sum_annual_funding_2023_2026\n        end as sum_annual_funding_2023_2026,\n        case\n            when sum_average_annual_funding_2018_2022 is null then 0\n            else sum_average_annual_funding_2018_2022\n        end as sum_average_annual_funding_2018_2022,\n    from msoa_mapping\n    left join aggregated on msoa_mapping.lad22nm = aggregated.local_authority\n)\n\n\nselect * from combined", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__ace_npo_funding_aggregated\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.847759Z", "completed_at": "2025-02-13T17:19:03.855233Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.857045Z", "completed_at": "2025-02-13T17:19:03.857051Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.016344785690307617, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.indices_of_deprivation", "compiled": true, "compiled_code": "select *\nfrom \"WMCSRP2\".\"md_raw\".\"raw__indices_of_deprivation\"\nwhere\n    msoa21cd in (\n        select msoa21cd from \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n    )", "relation_name": "\"WMCSRP2\".\"md_marts\".\"Indices of Deprivation\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.852097Z", "completed_at": "2025-02-13T17:19:03.857734Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.862173Z", "completed_at": "2025-02-13T17:19:03.862181Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.018957138061523438, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__ace_project_grants_aggregated", "compiled": true, "compiled_code": "with\n\nproject_grants as (\n    select * from \"WMCSRP2\".\"md_raw\".\"raw__ace_project_grants\"\n),\n\n\naggregated as (\n    select\n        sum(award_amount) as sum_award_amount,\n        local_authority\n    from\n        project_grants\n    group by\n        local_authority\n),\n\n\nmsoa_mapping as (\n    select\n        lad22cd,\n        lad22nm,\n        msoa21cd\n    from\n        \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n),\n\n\ncombined as (\n    select\n        distinct lad22cd,\n        lad22nm,\n        case\n            when sum_award_amount is null then 0\n            else sum_award_amount\n        end as sum_award_amount\n    from msoa_mapping\n    left join aggregated on msoa_mapping.lad22nm = aggregated.local_authority\n)\n\n\nselect * from combined", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__ace_project_grants_aggregated\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.858198Z", "completed_at": "2025-02-13T17:19:03.864075Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.866189Z", "completed_at": "2025-02-13T17:19:03.866196Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.011532068252563477, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__census_msoa_base", "compiled": true, "compiled_code": "with\n\nwmca_area_codes as (\n    select\n        distinct msoa21cd,\n        msoa21nm\n    from\n        \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n),\n\nmsoa_census as (\n    select\n        wac.msoa21cd,\n        wac.msoa21nm,\n        t.content,\n        t.measure,\n        t.count as count,\n        t.n as n\n    from\n        \"WMCSRP2\".\"md_raw\".\"raw__census\" as t\n    inner join\n        wmca_area_codes as wac\n    on\n        wac.msoa21cd = t.geography_code\n)\n\nselect\n    msoa21cd,\n    msoa21nm,\n    content,\n    rtrim(trim(regexp_replace(measure, '[\\s;]*measures: Value$', '')), ';') as measure,\n    count,\n    n\nfrom\n    msoa_census", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__census_msoa_base\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.870410Z", "completed_at": "2025-02-13T17:19:03.877819Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.879340Z", "completed_at": "2025-02-13T17:19:03.879349Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.01585078239440918, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__economic", "compiled": true, "compiled_code": "with\n\neconomic_data as (\n    select\n        local_authority,\n        measure,\n        value,\n        margin_of_error\n    from\n        \"WMCSRP2\".\"md_raw\".\"raw__economic\"\n),\n\nwmca_area_codes as (\n    select\n        lad22cd,\n        lad22nm,\n    from\n        \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n)\n\nselect\n    distinct ac.lad22cd,\n    ac.lad22nm,\n    ed.measure,\n    round(ed.value, 5) as value,\n    case\n        when margin_of_error < 0.05 then '<5%'\n        when margin_of_error < 0.1 then '5-10%'\n        when margin_of_error < 0.2 then '10-20%'\n    end as margin_of_error\nfrom\n    economic_data as ed\ninner join\n    wmca_area_codes as ac\non\n    ed.local_authority = ac.lad22nm", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__economic\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.867409Z", "completed_at": "2025-02-13T17:19:03.878283Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.880605Z", "completed_at": "2025-02-13T17:19:03.880614Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.01766681671142578, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__cultural_infrastructure", "compiled": true, "compiled_code": "with\n\nlad_codes as (\n    select distinct lad22nm, lad22cd\n    from \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n),\n\nservices_msoa as (\n    select\n        area_name as ladnm,\n        msoa21,\n        postcode,\n        service_type,\n        name as service_name,\n        source,\n        category,\n    from \"WMCSRP2\".\"md_raw\".\"raw__cultural_infrastructure\" as ci\n    left join \"WMCSRP2\".\"md_raw\".\"raw__postcode_mapping\" as pm\n    on ci.postcode = pm.pcd_no_space\n),\n\nservices_lad as (\n    select\n        *\n    from services_msoa\n    join lad_codes on services_msoa.ladnm = lad_codes.lad22nm\n)\n\nselect * from services_lad", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__cultural_infrastructure\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.874905Z", "completed_at": "2025-02-13T17:19:03.880126Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.884663Z", "completed_at": "2025-02-13T17:19:03.884672Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.01783919334411621, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__grant360", "compiled": true, "compiled_code": "with\n\npostcodes as (\n    select\n        msoa21,\n        pcd_no_space as postcode\n    from\n        \"WMCSRP2\".\"md_raw\".\"raw__postcode_mapping\"\n),\n\n\narea_codes as (\n    select\n        lad22cd,\n        lad22nm,\n        msoa21cd,\n    from\n        \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n),\n\n\ngrant360 as (\n    select\n        amount_awarded,\n        award_date,\n        recipient_org_name,\n        replace(recipient_org_postal_code, ' ', '') as recipient_org_postal_code,\n        funding_org_name\n    from\n        \"WMCSRP2\".\"md_raw\".\"raw__grant360\"\n),\n\n\ncombined as (\n    select\n        distinct area_codes.msoa21cd,\n        area_codes.lad22cd,\n        area_codes.lad22nm,\n        grant360.amount_awarded,\n        grant360.award_date,\n        grant360.recipient_org_name,\n        grant360.recipient_org_postal_code,\n        grant360.funding_org_name\n    from grant360\n    join postcodes on grant360.recipient_org_postal_code = postcodes.postcode\n    join area_codes on area_codes.msoa21cd = postcodes.msoa21\n)\n\n\nselect * from combined", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__grant360\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.881306Z", "completed_at": "2025-02-13T17:19:03.886810Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.888925Z", "completed_at": "2025-02-13T17:19:03.888932Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.014725923538208008, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__wellbeing", "compiled": true, "compiled_code": "with\n\nwellbeing_data as (\n    select\n        area_codes,\n        wellbeing_factor,\n        value,\n        margin_of_error \n    from\n        \"WMCSRP2\".\"md_raw\".\"raw__wellbeing\"\n),\n\nwmca_area_codes as (\n    select\n        lad22cd,\n        lad22nm\n    from\n        \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n)\n\nselect\n    distinct ac.lad22cd,\n    ac.lad22nm,\n    wd.wellbeing_factor,\n    wd.value,\n    wd.margin_of_error,\nfrom\n    wmca_area_codes as ac\nleft join\n    wellbeing_data as wd\non\n    wd.area_codes = ac.lad22cd", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__wellbeing\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.890673Z", "completed_at": "2025-02-13T17:19:03.899833Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.901532Z", "completed_at": "2025-02-13T17:19:03.901543Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.015460491180419922, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.west_midlands_area_codes", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"West Midlands Area Codes\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.894398Z", "completed_at": "2025-02-13T17:19:03.900942Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.907832Z", "completed_at": "2025-02-13T17:19:03.907841Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.020017385482788086, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.ace_npo_funding", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__ace_npo_funding_aggregated\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"Arts Council England NPO Funding\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.897497Z", "completed_at": "2025-02-13T17:19:03.907275Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.909296Z", "completed_at": "2025-02-13T17:19:03.909304Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.019733428955078125, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.ace_project_grants_funding", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__ace_project_grants_aggregated\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"Arts Council England Project Grants Funding\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.902316Z", "completed_at": "2025-02-13T17:19:03.910073Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.912174Z", "completed_at": "2025-02-13T17:19:03.912181Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.015358686447143555, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__census_msoa_with_population", "compiled": true, "compiled_code": "with msoa_census as (\n    select * from \"WMCSRP2\".\"md_warehouse\".\"int__census_msoa_base\"\n),\n\n\nmsoa_population as (\n    select * from \"WMCSRP2\".\"md_raw\".\"raw__msoa_population\"\n),\n\ncombined as (\n    select\n        msoa_census.msoa21cd,\n        msoa21nm,\n        content,\n        measure,\n        count,\n        n,\n        case\n            when n >= population then n+5\n            else population\n        end as population,\n    from msoa_census\n    join msoa_population on msoa_census.msoa21cd = msoa_population.msoa21cd\n)\n\nselect * from combined", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__census_msoa_with_population\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.915567Z", "completed_at": "2025-02-13T17:19:03.923975Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.925145Z", "completed_at": "2025-02-13T17:19:03.925154Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.014143228530883789, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.annual_population_survey_economic_measures", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__economic\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"Annual Population Survey Economic Measures\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.919104Z", "completed_at": "2025-02-13T17:19:03.925945Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.929817Z", "completed_at": "2025-02-13T17:19:03.929825Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.017146587371826172, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__cultural_infrastructure_lad", "compiled": true, "compiled_code": "with\n\ndistinct_services as (\n    select\n        distinct service_name,\n        lad22cd,\n        service_type\n    from \"WMCSRP2\".\"md_warehouse\".\"int__cultural_infrastructure\"\n)\n\nselect\n    lad22cd,\n    service_type,\n    count(service_name) as service_count\nfrom distinct_services\ngroup by lad22cd, service_type", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__cultural_infrastructure_lad\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.921586Z", "completed_at": "2025-02-13T17:19:03.926396Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.930748Z", "completed_at": "2025-02-13T17:19:03.930755Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.01691293716430664, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__cultural_infrastructure_msoa", "compiled": true, "compiled_code": "with\n\ndistinct_services as (\n    select\n        distinct service_name,\n        msoa21,\n        service_type\n    from \"WMCSRP2\".\"md_warehouse\".\"int__cultural_infrastructure\"\n)\n\nselect\n    msoa21,\n    service_type,\n    count(service_name) as service_count\nfrom distinct_services\ngroup by msoa21, service_type", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__cultural_infrastructure_msoa\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.926888Z", "completed_at": "2025-02-13T17:19:03.932634Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.934866Z", "completed_at": "2025-02-13T17:19:03.934873Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.016356468200683594, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.grant360_funding_data", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__grant360\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"Grant360 Funding Data\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.936083Z", "completed_at": "2025-02-13T17:19:03.942122Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.945057Z", "completed_at": "2025-02-13T17:19:03.945066Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.013593196868896484, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.annual_population_survey_welbeing_estimates", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__wellbeing\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"Annual Population Survey Wellbeing Estimates\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.939669Z", "completed_at": "2025-02-13T17:19:03.945846Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.946621Z", "completed_at": "2025-02-13T17:19:03.946626Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.012372016906738281, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__census_msoa_with_error", "compiled": true, "compiled_code": "with msoa_census as (\n    select * from \"WMCSRP2\".\"md_warehouse\".\"int__census_msoa_with_population\"\n),\n\n\nmsoa_errors as (\n    select\n        msoa21cd,\n        msoa21nm,\n        content as census_question,\n        measure as answer,\n        count as count_of_answer,\n        n as sample_size,\n        population as population_size,\n        count / n as p,\n        1.96 * sqrt( (p * (1-p)) / ((population - 1) * n / (population - n)) ) as margin_of_error\n    from\n        msoa_census\n)\n\n\nselect * from msoa_errors", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__census_msoa_with_error\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.942654Z", "completed_at": "2025-02-13T17:19:03.948039Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.949028Z", "completed_at": "2025-02-13T17:19:03.949034Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.013522624969482422, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.cultural_infrastructure", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__cultural_infrastructure_msoa\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"Cultural Infrastructure\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T17:19:03.950327Z", "completed_at": "2025-02-13T17:19:03.952748Z"}, {"name": "execute", "started_at": "2025-02-13T17:19:03.953185Z", "completed_at": "2025-02-13T17:19:03.953190Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.0047490596771240234, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.census", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__census_msoa_with_error\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"Census 2021 Data\"", "batch_results": null}], "elapsed_time": 0.37421226501464844, "args": {"select": [], "partial_parse_file_diff": true, "use_colors": true, "exclude": [], "populate_cache": true, "empty_catalog": false, "static": false, "strict_mode": false, "vars": {}, "show_resource_report": false, "log_file_max_bytes": 10485760, "cache_selected_only": false, "require_nested_cumulative_type_params": false, "send_anonymous_usage_stats": true, "log_format_file": "debug", "require_batched_execution_for_custom_microbatch_strategy": false, "state_modified_compare_more_unrendered_values": false, "profiles_dir": "/home/runner/work/wmcsrp-2/wmcsrp-2", "printer_width": 80, "require_yaml_configuration_for_mf_time_spines": false, "log_level": "info", "warn_error_options": {"include": [], "exclude": []}, "write_json": true, "log_path": "/home/runner/work/wmcsrp-2/wmcsrp-2/logs", "project_dir": "/home/runner/work/wmcsrp-2/wmcsrp-2", "partial_parse": true, "quiet": false, "source_freshness_run_project_hooks": false, "require_resource_names_without_spaces": false, "static_parser": true, "use_colors_file": true, "version_check": true, "print": true, "skip_nodes_if_on_run_start_fails": false, "log_level_file": "debug", "require_explicit_package_overrides_for_builtin_materializations": true, "compile": true, "favor_state": false, "state_modified_compare_vars": false, "which": "generate", "introspect": true, "invocation_command": "dbt docs generate", "defer": false, "macro_debugging": false, "log_format": "default", "indirect_selection": "eager"}}
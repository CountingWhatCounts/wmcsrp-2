{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/run-results/v6.json", "dbt_version": "1.9.2", "generated_at": "2025-02-13T15:12:17.422523Z", "invocation_id": "f49b117b-5dc2-4968-bfe2-3770bff5a442", "env": {}}, "results": [{"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.299521Z", "completed_at": "2025-02-13T15:12:17.317295Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.317663Z", "completed_at": "2025-02-13T15:12:17.317673Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.019974231719970703, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__ace_levelling_up_for_culture_places", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='ace_levelling_up_for_culture_places')\n\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_csv(io.BytesIO(data))\n    df.columns = [x.lower() for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__ace_levelling_up_for_culture_places\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__ace_levelling_up_for_culture_places\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__ace_levelling_up_for_culture_places\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.313433Z", "completed_at": "2025-02-13T15:12:17.319551Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.320521Z", "completed_at": "2025-02-13T15:12:17.320525Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.02224898338317871, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__ace_priority_places", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='ace_priority_places')\n\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_csv(io.BytesIO(data))\n    df.columns = [x.lower() for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__ace_priority_places\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__ace_priority_places\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__ace_priority_places\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.311906Z", "completed_at": "2025-02-13T15:12:17.319809Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.320880Z", "completed_at": "2025-02-13T15:12:17.320883Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.02282118797302246, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__ace_npo_funding", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='ace_npo_funding')\n\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_excel(io.BytesIO(data), sheet_name='data', engine=\"openpyxl\")\n    df.columns = [x.lower().replace(' ','_').replace('\\n', '_').replace('/','_').replace('(','_').replace(')','_') for x in df.columns]\n    df = df.rename(columns={\n        \"2018-22_average_annual_funding__figure_accurate_at_april_2018_\": \"average_annual_funding_2018_22\",\n        \"2022_23_annual_funding__extension_year_\": \"annual_funding__extension_year_2022_23\",\n        \"2023-26_annual_funding__offered_4_nov_2022_\": \"annual_funding__offered_4_nov_2022_2023_26\",\n    })\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__ace_npo_funding\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__ace_npo_funding\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__ace_npo_funding\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.314876Z", "completed_at": "2025-02-13T15:12:17.319991Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.321206Z", "completed_at": "2025-02-13T15:12:17.321210Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.022719860076904297, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__ace_project_grants", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='ace_project_grants')\n\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_excel(io.BytesIO(data), sheet_name='Project Grants Awards', engine=\"openpyxl\")\n    df.columns = df.iloc[1, :]\n    df = df.iloc[2:, :]\n    df.columns = [x.lower().replace(' ','_') for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__ace_project_grants\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__ace_project_grants\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__ace_project_grants\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.322475Z", "completed_at": "2025-02-13T15:12:17.325591Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.331003Z", "completed_at": "2025-02-13T15:12:17.331007Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.010795831680297852, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__census", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef get_geography_from_filename(filename: str) -> str:\n    return filename.split('.')[0].split('-')[2]\n\n\ndef process_age_data(age_data: pd.DataFrame) -> pd.DataFrame:\n    column_groups = {\n        'Age: Age 16-19': ['Age: Aged 16 to 19 years; measures: Value'],\n        'Age: Age 20-24': ['Age: Aged 20 to 24 years; measures: Value'],\n        'Age: Age 25-29': [\n            'Age: Aged 25 years; measures: Value',\n            'Age: Aged 26 years; measures: Value',\n            'Age: Aged 27 years; measures: Value',\n            'Age: Aged 28 years; measures: Value',\n            'Age: Aged 29 years; measures: Value'\n        ],\n        'Age: Age 30-34': [\n            'Age: Aged 30 years; measures: Value',\n            'Age: Aged 31 years; measures: Value',\n            'Age: Aged 32 years; measures: Value',\n            'Age: Aged 33 years; measures: Value',\n            'Age: Aged 34 years; measures: Value'\n        ],\n        'Age: Age 35-39': [\n            'Age: Aged 35 years; measures: Value',\n            'Age: Aged 36 years; measures: Value',\n            'Age: Aged 37 years; measures: Value',\n            'Age: Aged 38 years; measures: Value',\n            'Age: Aged 39 years; measures: Value'\n        ],\n        'Age: Age 40-44': [\n            'Age: Aged 40 years; measures: Value',\n            'Age: Aged 41 years; measures: Value',\n            'Age: Aged 42 years; measures: Value',\n            'Age: Aged 43 years; measures: Value',\n            'Age: Aged 44 years; measures: Value'\n        ],\n        'Age: Age 45-49': [\n            'Age: Aged 45 years; measures: Value',\n            'Age: Aged 46 years; measures: Value',\n            'Age: Aged 47 years; measures: Value',\n            'Age: Aged 48 years; measures: Value',\n            'Age: Aged 49 years; measures: Value'\n        ],\n        'Age: Age 50-54': [\n            'Age: Aged 50 years; measures: Value',\n            'Age: Aged 51 years; measures: Value',\n            'Age: Aged 52 years; measures: Value',\n            'Age: Aged 53 years; measures: Value',\n            'Age: Aged 54 years; measures: Value'\n        ],\n        'Age: Age 55-59': [\n            'Age: Aged 55 years; measures: Value',\n            'Age: Aged 56 years; measures: Value',\n            'Age: Aged 57 years; measures: Value',\n            'Age: Aged 58 years; measures: Value',\n            'Age: Aged 59 years; measures: Value'\n        ],\n        'Age: Age 60-64': [\n            'Age: Aged 60 years; measures: Value',\n            'Age: Aged 61 years; measures: Value',\n            'Age: Aged 62 years; measures: Value',\n            'Age: Aged 63 years; measures: Value',\n            'Age: Aged 64 years; measures: Value'\n        ],\n        'Age: Age 65-69': [\n            'Age: Aged 65 years; measures: Value',\n            'Age: Aged 66 years; measures: Value',\n            'Age: Aged 67 years; measures: Value',\n            'Age: Aged 68 years; measures: Value',\n            'Age: Aged 69 years; measures: Value'\n        ],\n        'Age: Age 70-74': [\n            'Age: Aged 70 years; measures: Value',\n            'Age: Aged 71 years; measures: Value',\n            'Age: Aged 72 years; measures: Value',\n            'Age: Aged 73 years; measures: Value',\n            'Age: Aged 74 years; measures: Value'\n        ],\n        'Age: Age 75-79': [\n            'Age: Aged 75 years; measures: Value',\n            'Age: Aged 76 years; measures: Value',\n            'Age: Aged 77 years; measures: Value',\n            'Age: Aged 78 years; measures: Value',\n            'Age: Aged 79 years; measures: Value'\n        ],\n        'Age: Age 80-84': [\n            'Age: Aged 80 years; measures: Value',\n            'Age: Aged 81 years; measures: Value',\n            'Age: Aged 82 years; measures: Value',\n            'Age: Aged 83 years; measures: Value',\n            'Age: Aged 84 years; measures: Value'\n        ],\n        'Age: Age 85 and over': ['Age: Aged 85 years and over; measures: Value']\n        \n    }\n\n    df = age_data.copy()\n    for new_col, existing_columns in column_groups.items():\n        df[new_col] = df[existing_columns].sum(axis=1)\n\n    final_columns = ['date','geography','geography code','Age: Total; measures: Value'] + list(column_groups.keys())\n    df = df[final_columns]\n\n    return df\n\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='census')\n\n    frames = []\n    for blob in blobs:\n        if not blob.name.endswith('.csv'):\n            continue\n\n        geography = get_geography_from_filename(blob.name)    \n        if 'msoa' not in blob.name: # Only process MSOA data\n            continue\n            \n        try:\n            data = blob.download_as_bytes()\n            df = pd.read_csv(io.BytesIO(data))\n        except pd.errors.EmptyDataError as e:\n            continue\n\n        # If age data then preprocess\n        if 'ts007' in blob.name:\n            df = process_age_data(df)\n\n        total_column = [col for col in df.columns if 'Total' in col or 'All persons' in col][0] # Get total column\n        data_content = total_column.split(':')[0] # Get data content from column\n        value_columns = [col for col in df.columns if col not in ['date', 'geography', 'geography code', total_column]] # Get value columns\n\n        df_totals = df[['date', 'geography', 'geography code', total_column]].drop_duplicates()\n        df_values = df[['geography code'] + value_columns]\n        df_values = df_values.melt(\n            id_vars='geography code',\n            var_name='measure',\n            value_name='count'\n        )\n\n        df = df_totals.merge(df_values, how='left', on='geography code')\n        df = df.rename(columns={total_column: 'n', 'date': 'year'})\n\n        df['content'] = data_content\n        df['geography'] = geography\n        df = df[df['measure']!=total_column]\n        df['measure'] = df['measure'].apply(lambda x: (':').join(x.split(':')[1:]))\n        frames.append(df)\n\n    df = pd.concat(frames)\n    df.columns = [x.lower().replace(' ','_') for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__census\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__census\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__census\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.325776Z", "completed_at": "2025-02-13T15:12:17.331640Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.332424Z", "completed_at": "2025-02-13T15:12:17.332427Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.008239030838012695, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__cultural_infrastructure", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='services')\n\n    frames = []\n    for blob in blobs:\n        data = blob.download_as_bytes()\n        df = pd.read_csv(io.BytesIO(data))\n        df.columns = [x.lower().replace(' ', '_').replace('(', '').replace(')', '').replace(':', '_') for x in df.columns]\n        frames.append(df)\n    df = pd.concat(frames)\n    df = df.drop('amount_awarded', axis=1)\n    df['postcode'] = df['postcode'].apply(lambda x: x.replace(' ', ''))\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__cultural_infrastructure\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__cultural_infrastructure\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__cultural_infrastructure\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.327426Z", "completed_at": "2025-02-13T15:12:17.332228Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.333253Z", "completed_at": "2025-02-13T15:12:17.333256Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.009827136993408203, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__economic", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport numpy as np\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef filter_columns(df: pd.DataFrame):\n    column_indices = [0]\n    i = 0\n    while i < len(df.columns):\n        if i + 3 < len(df.columns):\n            column_indices.extend([i + 3, i + 4])\n        i += 4\n\n    df = df.iloc[:, column_indices]\n    return df\n\n\n\ndef model(dbt, session):\n    \n    pd.set_option('future.no_silent_downcasting', True)\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='economic')\n\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n    df = pd.read_csv(io.BytesIO(data))\n\n    df.columns = df.loc[5,:]\n    df = df.loc[7:, :]\n    df = filter_columns(df)\n\n    new_columns = []\n    new_columns.append(df.columns[0])\n    i = 1\n    while i < len(df.columns):\n        if i + 1 < len(df.columns):\n            new_columns.append(df.columns[i] + ' - Value')\n            new_columns.append(df.columns[i] + ' - Margin of Error')\n        i += 2\n    df.columns = new_columns\n\n    df = df.replace(['#', '-', '!', '*', '~'], np.nan)\n    df = df.dropna(how='all')\n\n    local_authority_col = 'local authority: district / unitary (as of April 2021)'\n\n    # Identify value and margin columns\n    value_columns = [col for col in df.columns if 'Value' in col]\n\n    # Create a mapping from 'Value' columns to their corresponding 'Margin of Error' columns\n    value_to_margin_map = {\n        value_col: value_col.replace('Value', 'Margin of Error')\n        for value_col in value_columns\n    }\n\n    # Prepare an empty DataFrame to store the melted data\n    melted_df = pd.DataFrame()\n\n    # Melt the DataFrame for each pair of value and margin columns\n    for value_col, margin_col in value_to_margin_map.items():\n        temp_df = df[[local_authority_col, value_col, margin_col]].copy()\n        temp_df.columns = ['local authority', 'value', 'margin of error']\n        temp_df['measure'] = value_col.replace(' - Value', '')\n        melted_df = pd.concat([melted_df, temp_df], ignore_index=True)\n\n    melted_df = melted_df.reset_index(names='ID')\n    melted_df = melted_df[['ID', 'local authority', 'measure', 'value', 'margin of error']]\n    melted_df['value'] = melted_df['value'].apply(lambda x: float(x) / 100)\n    melted_df['margin of error'] = melted_df['margin of error'].apply(lambda x: float(x) / 100)\n    melted_df.columns = [x.lower().replace(' ','_') for x in melted_df.columns]\n\n    return melted_df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__economic\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__economic\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__economic\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.329290Z", "completed_at": "2025-02-13T15:12:17.332753Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.334975Z", "completed_at": "2025-02-13T15:12:17.334979Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.010316133499145508, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__grant360", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='grant360')\n\n    frames = []\n    for blob in blobs:\n        data = blob.download_as_bytes()\n        df = pd.read_csv(io.BytesIO(data))\n        df.columns = [x.lower().replace(' ', '_').replace('(', '').replace(')', '').replace(':', '_') for x in df.columns]\n        frames.append(df)\n    df = pd.concat(frames)\n    \n    df['award_date'] = df['award_date'].astype(str)\n    df['award_date'] = df['award_date'].apply(lambda x: x.replace('/', '-'))\n    df['award_date'] = df['award_date'].apply(lambda x: pd.to_datetime(x).strftime('%Y-%m-%d'))\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__grant360\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__grant360\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__grant360\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.336235Z", "completed_at": "2025-02-13T15:12:17.342102Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.344386Z", "completed_at": "2025-02-13T15:12:17.344392Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.011487960815429688, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__indices_of_deprivation", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='indices_of_deprivation')\n    \n    for blob in blobs:\n        if blob.name.endswith('.csv'):\n            data = blob.download_as_bytes()\n    df = pd.read_csv(io.BytesIO(data))\n    df.columns = [x.lower().replace(' ', '_') for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__indices_of_deprivation\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__indices_of_deprivation\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__indices_of_deprivation\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.338815Z", "completed_at": "2025-02-13T15:12:17.344139Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.345030Z", "completed_at": "2025-02-13T15:12:17.345033Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.009308815002441406, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__msoa_mapping", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='msoa_mapping')\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_csv(io.BytesIO(data))\n    df.columns = [x.lower() for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__msoa_mapping\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__msoa_mapping\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__msoa_mapping\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.340566Z", "completed_at": "2025-02-13T15:12:17.344827Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.345624Z", "completed_at": "2025-02-13T15:12:17.345626Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.007709980010986328, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__msoa_population", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='msoa_population')\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_excel(io.BytesIO(data), sheet_name='Mid-2021 MSOA 2021', engine='openpyxl')\n    df.columns = df.iloc[2, :]\n    df = df.iloc[3:, :]\n    df = df[['MSOA 2021 Code', 'Total']]\n    df.columns = [x.lower().replace(' ', '_') for x in df.columns]\n    df = df.rename(columns={'msoa_2021_code': 'msoa21cd', 'total': 'population'})\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__msoa_population\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__msoa_population\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__msoa_population\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.342352Z", "completed_at": "2025-02-13T15:12:17.345915Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.346830Z", "completed_at": "2025-02-13T15:12:17.346832Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.008487939834594727, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__postcode_mapping", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nimport numpy as np\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='postcode_mapping')\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_csv(io.BytesIO(data))\n    df = df.replace(r'^\\s*$', np.nan, regex=True)\n    df.columns = [x.lower() for x in df.columns]\n    df['pcd_no_space'] = df['pcd2'].apply(lambda x: x.replace(' ', ''))\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__postcode_mapping\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__postcode_mapping\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__postcode_mapping\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.348122Z", "completed_at": "2025-02-13T15:12:17.353486Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.355287Z", "completed_at": "2025-02-13T15:12:17.355290Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.00897526741027832, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__rural_urban_classification", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nimport numpy as np\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='rural_urban_classification')\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_csv(io.BytesIO(data))\n    df.columns = [x.lower() for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__rural_urban_classification\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__rural_urban_classification\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__rural_urban_classification\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.350273Z", "completed_at": "2025-02-13T15:12:17.355014Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.355847Z", "completed_at": "2025-02-13T15:12:17.355849Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.008764028549194336, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__wellbeing", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nimport numpy as np\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    pd.set_option('future.no_silent_downcasting', True)\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='wellbeing')\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    sheets = {\n        '1 Life satisfaction means': 11,\n        '4 Worthwhile means': 11,\n        '7 Happiness means': 11,\n        '10 Anxiety means': 12\n    }\n\n    sheet_frames = []\n\n    for sheet, columns_row in sheets.items():\n\n        df = pd.read_excel(io.BytesIO(data), sheet_name=sheet, engine='openpyxl')\n        df.columns = df.iloc[columns_row,:]\n        df = df.iloc[columns_row+1:,1:]\n\n        df = df.replace('[cv1]', '<5%')\n        df = df.replace('[cv2]', '5-10%')\n        df = df.replace('[cv3]', '10-20%')\n        df = df.replace('[cv4]', '>20%')\n        df = df.replace('[u]', np.nan)\n        df = df.replace('[x]', np.nan)\n\n        index_column = 'Area Codes'\n\n        melted_df = pd.DataFrame()\n        i = 1\n        while i < len(df.columns):\n            value_column = df.columns[i]\n            error_column = df.columns[i+1]\n            temp_df = df[[index_column, value_column, error_column]].copy()\n            temp_df['date'] = value_column\n            temp_df.columns = ['area codes', 'value', 'margin of error', 'date']\n            melted_df = pd.concat([melted_df, temp_df], ignore_index=True)\n            i += 2\n\n        melted_df['wellbeing_factor'] = sheet\n        sheet_frames.append(melted_df)\n    df = pd.concat(sheet_frames)\n\n    df['wellbeing_factor'] = df['wellbeing_factor'].apply(lambda x: ' '.join(x.split(' ')[1:]))\n    df['value'] = df['value'].astype(float)\n    df = df.reset_index(names='ID')\n    df.columns = [x.lower().replace(' ','_') for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__wellbeing\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__wellbeing\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__wellbeing\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.351825Z", "completed_at": "2025-02-13T15:12:17.355657Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.356591Z", "completed_at": "2025-02-13T15:12:17.356593Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.00912618637084961, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.ace_levelling_up_for_culture_places", "compiled": true, "compiled_code": "select\n    *\nfrom\n    \"WMCSRP2\".\"md_raw\".\"raw__ace_levelling_up_for_culture_places\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"ace_levelling_up_for_culture_places\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.353723Z", "completed_at": "2025-02-13T15:12:17.356398Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.357346Z", "completed_at": "2025-02-13T15:12:17.357348Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.007338047027587891, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.ace_priority_places", "compiled": true, "compiled_code": "select\n    *\nfrom\n    \"WMCSRP2\".\"md_raw\".\"raw__ace_priority_places\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"ace_priority_places\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.359786Z", "completed_at": "2025-02-13T15:12:17.361648Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.362045Z", "completed_at": "2025-02-13T15:12:17.362047Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.004425048828125, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__rural_urban_classification", "compiled": true, "compiled_code": "with\n\nruc as (\n    select * from \"WMCSRP2\".\"md_raw\".\"raw__rural_urban_classification\"\n),\n\nmsoa_mapping as (\n    select * from \"WMCSRP2\".\"md_raw\".\"raw__msoa_mapping\"\n),\n\ncombined as (\n    select\n        ruc.msoa11cd,\n        ruc.msoa11nm,\n        ruc11cd,\n        ruc11\n    from ruc\n    left join msoa_mapping\n    on ruc.msoa11cd = msoa_mapping.msoa11cd\n)\n\nselect * from combined", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__rural_urban_classification\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.358321Z", "completed_at": "2025-02-13T15:12:17.361840Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.362360Z", "completed_at": "2025-02-13T15:12:17.362362Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.005272626876831055, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__area_codes", "compiled": true, "compiled_code": "with\n\ntarget_areas as (\n    select\n        case\n            when lad22nm in (\n                'Birmingham',\n                'Coventry',\n                'Dudley',\n                'Sandwell',\n                'Solihull',\n                'Walsall',\n                'Wolverhampton'\n            ) then 'WMCA Constituent Member'\n            when lad22nm in (\n                'Cannock Chase',\n                'North Warwickshire',\n                'Nuneaton and Bedworth',\n                'Redditch',\n                'Rugby',\n                'Shropshire',\n                'Stratford-on-Avon',\n                'Tamworth',\n                'Telford and Wrekin',\n                'Warwick'\n            ) then 'WMCA Non-Constituent Member'\n            when lad22nm in (\n                'Bromsgrove',\n                'East Staffordshire',\n                'Herefordshire, County of',\n                'Lichfield',\n                'Malvern Hills',\n                'Newcastle-under-Lyme',\n                'South Staffordshire',\n                'Stafford',\n                'Staffordshire Moorlands',\n                'Stoke-on-Trent',\n                'Worcester',\n                'Wychavon',\n                'Wyre Forest'\n            ) then 'West Midlands Non-WMCA'\n            else 'Ignore'\n        end as area,\n        lad22cd,\n        lad22nm,\n        msoa21cd,\n        msoa21nm\n    from\n        \"WMCSRP2\".\"md_raw\".\"raw__msoa_mapping\"\n)\n\nselect * from target_areas where area != 'Ignore'", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.365040Z", "completed_at": "2025-02-13T15:12:17.372073Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.372641Z", "completed_at": "2025-02-13T15:12:17.372644Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.009304046630859375, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.rural_urban_classification", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__rural_urban_classification\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"rural_urban_classification\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.366646Z", "completed_at": "2025-02-13T15:12:17.372412Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.373185Z", "completed_at": "2025-02-13T15:12:17.373188Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.009415864944458008, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.area_codes", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"area_codes\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.369025Z", "completed_at": "2025-02-13T15:12:17.372979Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.373935Z", "completed_at": "2025-02-13T15:12:17.373937Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.009943008422851562, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.indices_of_deprivation", "compiled": true, "compiled_code": "select *\nfrom \"WMCSRP2\".\"md_raw\".\"raw__indices_of_deprivation\"\nwhere\n    msoa21cd in (\n        select msoa21cd from \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n    )", "relation_name": "\"WMCSRP2\".\"md_marts\".\"indices_of_deprivation\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.370424Z", "completed_at": "2025-02-13T15:12:17.373509Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.374430Z", "completed_at": "2025-02-13T15:12:17.374433Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.010039091110229492, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__ace_npo_funding_aggregated", "compiled": true, "compiled_code": "with npo_funding as (\n    select * from \"WMCSRP2\".\"md_raw\".\"raw__ace_npo_funding\"\n),\n\n\naggregated as (\n    select\n        sum(annual_funding__extension_year_2022_23) as sum_annual_funding_extension_year,\n        sum(annual_funding__offered_4_nov_2022_2023_26) as sum_annual_funding_2023_2026,\n        sum(average_annual_funding_2018_22) sum_average_annual_funding_2018_2022,\n        local_authority\n    from\n        npo_funding\n    group by\n        local_authority\n),\n\nmsoa_mapping as (\n    select\n        lad22cd,\n        lad22nm\n    from\n        \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n),\n\n\ncombined as (\n    select\n        distinct lad22cd,\n        lad22nm,\n        case\n            when sum_annual_funding_extension_year is null then 0\n            else sum_annual_funding_extension_year\n        end as sum_annual_funding_extension_year,\n        case\n            when sum_annual_funding_2023_2026 is null then 0\n            else sum_annual_funding_2023_2026\n        end as sum_annual_funding_2023_2026,\n        case\n            when sum_average_annual_funding_2018_2022 is null then 0\n            else sum_average_annual_funding_2018_2022\n        end as sum_average_annual_funding_2018_2022,\n    from msoa_mapping\n    left join aggregated on msoa_mapping.lad22nm = aggregated.local_authority\n)\n\n\nselect * from combined", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__ace_npo_funding_aggregated\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.376480Z", "completed_at": "2025-02-13T15:12:17.382928Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.383219Z", "completed_at": "2025-02-13T15:12:17.383223Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.008537054061889648, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__ace_project_grants_aggregated", "compiled": true, "compiled_code": "with\n\nproject_grants as (\n    select * from \"WMCSRP2\".\"md_raw\".\"raw__ace_project_grants\"\n),\n\n\naggregated as (\n    select\n        sum(award_amount) as sum_award_amount,\n        local_authority\n    from\n        project_grants\n    group by\n        local_authority\n),\n\n\nmsoa_mapping as (\n    select\n        lad22cd,\n        lad22nm,\n        msoa21cd\n    from\n        \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n),\n\n\ncombined as (\n    select\n        distinct lad22cd,\n        lad22nm,\n        case\n            when sum_award_amount is null then 0\n            else sum_award_amount\n        end as sum_award_amount\n    from msoa_mapping\n    left join aggregated on msoa_mapping.lad22nm = aggregated.local_authority\n)\n\n\nselect * from combined", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__ace_project_grants_aggregated\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.378222Z", "completed_at": "2025-02-13T15:12:17.383546Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.384553Z", "completed_at": "2025-02-13T15:12:17.384556Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.009417057037353516, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__census_msoa_base", "compiled": true, "compiled_code": "with\n\nwmca_area_codes as (\n    select\n        distinct msoa21cd,\n        msoa21nm\n    from\n        \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n),\n\nmsoa_census as (\n    select\n        wac.msoa21cd,\n        wac.msoa21nm,\n        t.content,\n        t.measure,\n        t.count as count,\n        t.n as n\n    from\n        \"WMCSRP2\".\"md_raw\".\"raw__census\" as t\n    inner join\n        wmca_area_codes as wac\n    on\n        wac.msoa21cd = t.geography_code\n)\n\nselect\n    msoa21cd,\n    msoa21nm,\n    content,\n    rtrim(trim(regexp_replace(measure, '[\\s;]*measures: Value$', '')), ';') as measure,\n    count,\n    n\nfrom\n    msoa_census", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__census_msoa_base\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.379898Z", "completed_at": "2025-02-13T15:12:17.383863Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.384866Z", "completed_at": "2025-02-13T15:12:17.384868Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.009048700332641602, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__cultural_infrastructure", "compiled": true, "compiled_code": "with\n\nlad_codes as (\n    select distinct lad22nm, lad22cd\n    from \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n),\n\nservices_msoa as (\n    select\n        area_name as ladnm,\n        msoa21,\n        postcode,\n        service_type,\n        name as service_name,\n        source,\n        category,\n    from \"WMCSRP2\".\"md_raw\".\"raw__cultural_infrastructure\" as ci\n    left join \"WMCSRP2\".\"md_raw\".\"raw__postcode_mapping\" as pm\n    on ci.postcode = pm.pcd_no_space\n),\n\nservices_lad as (\n    select\n        *\n    from services_msoa\n    join lad_codes on services_msoa.ladnm = lad_codes.lad22nm\n)\n\nselect * from services_lad", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__cultural_infrastructure\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.381493Z", "completed_at": "2025-02-13T15:12:17.384290Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.385393Z", "completed_at": "2025-02-13T15:12:17.385394Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.009190082550048828, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__economic", "compiled": true, "compiled_code": "with\n\neconomic_data as (\n    select\n        local_authority,\n        measure,\n        value,\n        margin_of_error\n    from\n        \"WMCSRP2\".\"md_raw\".\"raw__economic\"\n),\n\nwmca_area_codes as (\n    select\n        lad22cd,\n        lad22nm,\n    from\n        \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n)\n\nselect\n    distinct ac.lad22cd,\n    ac.lad22nm,\n    ed.measure,\n    round(ed.value, 5) as value,\n    case\n        when margin_of_error < 0.05 then '<5%'\n        when margin_of_error < 0.1 then '5-10%'\n        when margin_of_error < 0.2 then '10-20%'\n    end as margin_of_error\nfrom\n    economic_data as ed\ninner join\n    wmca_area_codes as ac\non\n    ed.local_authority = ac.lad22nm", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__economic\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.387017Z", "completed_at": "2025-02-13T15:12:17.392351Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.393842Z", "completed_at": "2025-02-13T15:12:17.393846Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.008732795715332031, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__grant360", "compiled": true, "compiled_code": "with\n\npostcodes as (\n    select\n        msoa21,\n        pcd_no_space as postcode\n    from\n        \"WMCSRP2\".\"md_raw\".\"raw__postcode_mapping\"\n),\n\n\narea_codes as (\n    select\n        lad22cd,\n        lad22nm,\n        msoa21cd,\n    from\n        \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n),\n\n\ngrant360 as (\n    select\n        amount_awarded,\n        award_date,\n        recipient_org_name,\n        replace(recipient_org_postal_code, ' ', '') as recipient_org_postal_code,\n        funding_org_name\n    from\n        \"WMCSRP2\".\"md_raw\".\"raw__grant360\"\n),\n\n\ncombined as (\n    select\n        distinct area_codes.msoa21cd,\n        area_codes.lad22cd,\n        area_codes.lad22nm,\n        grant360.amount_awarded,\n        grant360.award_date,\n        grant360.recipient_org_name,\n        grant360.recipient_org_postal_code,\n        grant360.funding_org_name\n    from grant360\n    join postcodes on grant360.recipient_org_postal_code = postcodes.postcode\n    join area_codes on area_codes.msoa21cd = postcodes.msoa21\n)\n\n\nselect * from combined", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__grant360\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.389531Z", "completed_at": "2025-02-13T15:12:17.394338Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.395081Z", "completed_at": "2025-02-13T15:12:17.395086Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.008543968200683594, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__wellbeing", "compiled": true, "compiled_code": "with\n\nwellbeing_data as (\n    select\n        area_codes,\n        wellbeing_factor,\n        value,\n        margin_of_error \n    from\n        \"WMCSRP2\".\"md_raw\".\"raw__wellbeing\"\n),\n\nwmca_area_codes as (\n    select\n        lad22cd,\n        lad22nm\n    from\n        \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n)\n\nselect\n    distinct ac.lad22cd,\n    ac.lad22nm,\n    wd.wellbeing_factor,\n    wd.value,\n    wd.margin_of_error,\nfrom\n    wmca_area_codes as ac\nleft join\n    wellbeing_data as wd\non\n    wd.area_codes = ac.lad22cd", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__wellbeing\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.391105Z", "completed_at": "2025-02-13T15:12:17.394765Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.395951Z", "completed_at": "2025-02-13T15:12:17.395955Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.009193897247314453, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.ace_npo_funding", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__ace_npo_funding_aggregated\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"ace_npo_funding\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.392540Z", "completed_at": "2025-02-13T15:12:17.395416Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.396655Z", "completed_at": "2025-02-13T15:12:17.396658Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.008033990859985352, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.ace_project_grants", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__ace_project_grants_aggregated\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"ace_project_grants\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.397955Z", "completed_at": "2025-02-13T15:12:17.401984Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.406272Z", "completed_at": "2025-02-13T15:12:17.406279Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.010718822479248047, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__census_msoa_with_population", "compiled": true, "compiled_code": "with msoa_census as (\n    select * from \"WMCSRP2\".\"md_warehouse\".\"int__census_msoa_base\"\n),\n\n\nmsoa_population as (\n    select * from \"WMCSRP2\".\"md_raw\".\"raw__msoa_population\"\n),\n\ncombined as (\n    select\n        msoa_census.msoa21cd,\n        msoa21nm,\n        content,\n        measure,\n        count,\n        n,\n        case\n            when n >= population then n+5\n            else population\n        end as population,\n    from msoa_census\n    join msoa_population on msoa_census.msoa21cd = msoa_population.msoa21cd\n)\n\nselect * from combined", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__census_msoa_with_population\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.400438Z", "completed_at": "2025-02-13T15:12:17.406736Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.407371Z", "completed_at": "2025-02-13T15:12:17.407373Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.009931087493896484, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__cultural_infrastructure_lad", "compiled": true, "compiled_code": "with\n\ndistinct_services as (\n    select\n        distinct service_name,\n        lad22cd,\n        service_type\n    from \"WMCSRP2\".\"md_warehouse\".\"int__cultural_infrastructure\"\n)\n\nselect\n    lad22cd,\n    service_type,\n    count(service_name) as service_count\nfrom distinct_services\ngroup by lad22cd, service_type", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__cultural_infrastructure_lad\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.403479Z", "completed_at": "2025-02-13T15:12:17.407695Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.408497Z", "completed_at": "2025-02-13T15:12:17.408499Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.008591890335083008, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.economic", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__economic\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"economic\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.402173Z", "completed_at": "2025-02-13T15:12:17.408079Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.409002Z", "completed_at": "2025-02-13T15:12:17.409004Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.009510993957519531, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__cultural_infrastructure_msoa", "compiled": true, "compiled_code": "with\n\ndistinct_services as (\n    select\n        distinct service_name,\n        msoa21,\n        service_type\n    from \"WMCSRP2\".\"md_warehouse\".\"int__cultural_infrastructure\"\n)\n\nselect\n    msoa21,\n    service_type,\n    count(service_name) as service_count\nfrom distinct_services\ngroup by msoa21, service_type", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__cultural_infrastructure_msoa\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.409694Z", "completed_at": "2025-02-13T15:12:17.413664Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.415350Z", "completed_at": "2025-02-13T15:12:17.415353Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.007511138916015625, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.grant360", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__grant360\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"grant360\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.411929Z", "completed_at": "2025-02-13T15:12:17.415634Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.417121Z", "completed_at": "2025-02-13T15:12:17.417124Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.007883071899414062, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.wellbeing", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__wellbeing\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"wellbeing\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.414074Z", "completed_at": "2025-02-13T15:12:17.417453Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.417884Z", "completed_at": "2025-02-13T15:12:17.417886Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.006232023239135742, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__census_msoa_with_error", "compiled": true, "compiled_code": "with msoa_census as (\n    select * from \"WMCSRP2\".\"md_warehouse\".\"int__census_msoa_with_population\"\n),\n\n\nmsoa_errors as (\n    select\n        msoa21cd,\n        msoa21nm,\n        content as census_question,\n        measure as answer,\n        count as count_of_answer,\n        n as sample_size,\n        population as population_size,\n        count / n as p,\n        1.96 * sqrt( (p * (1-p)) / ((population - 1) * n / (population - n)) ) as margin_of_error\n    from\n        msoa_census\n)\n\n\nselect * from msoa_errors", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__census_msoa_with_error\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.415830Z", "completed_at": "2025-02-13T15:12:17.417706Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.418199Z", "completed_at": "2025-02-13T15:12:17.418201Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.0049779415130615234, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.cultural_infrastructure", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__cultural_infrastructure_msoa\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"cultural_infrastructure\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T15:12:17.419198Z", "completed_at": "2025-02-13T15:12:17.420844Z"}, {"name": "execute", "started_at": "2025-02-13T15:12:17.421028Z", "completed_at": "2025-02-13T15:12:17.421030Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.0022640228271484375, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.census", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__census_msoa_with_error\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"census\"", "batch_results": null}], "elapsed_time": 0.19636201858520508, "args": {"send_anonymous_usage_stats": true, "state_modified_compare_vars": false, "state_modified_compare_more_unrendered_values": false, "static_parser": true, "compile": true, "invocation_command": "dbt docs generate", "version_check": true, "strict_mode": false, "quiet": false, "select": [], "favor_state": false, "defer": false, "require_nested_cumulative_type_params": false, "partial_parse_file_diff": true, "printer_width": 80, "static": false, "require_batched_execution_for_custom_microbatch_strategy": false, "warn_error_options": {"include": [], "exclude": []}, "partial_parse": true, "indirect_selection": "eager", "log_format": "default", "cache_selected_only": false, "vars": {}, "log_path": "/Users/marc.dunford/development/counting_what_counts/wmcsrp-2/logs", "use_colors": true, "log_level_file": "debug", "show_resource_report": false, "introspect": true, "profiles_dir": "/Users/marc.dunford/development/counting_what_counts/wmcsrp-2", "exclude": [], "log_format_file": "debug", "require_resource_names_without_spaces": false, "print": true, "project_dir": "/Users/marc.dunford/development/counting_what_counts/wmcsrp-2", "require_yaml_configuration_for_mf_time_spines": false, "use_colors_file": true, "which": "generate", "source_freshness_run_project_hooks": false, "populate_cache": true, "macro_debugging": false, "require_explicit_package_overrides_for_builtin_materializations": true, "empty_catalog": false, "write_json": true, "log_level": "info", "log_file_max_bytes": 10485760, "skip_nodes_if_on_run_start_fails": false}}
{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/run-results/v6.json", "dbt_version": "1.9.2", "generated_at": "2025-02-13T16:58:48.960596Z", "invocation_id": "822da459-5dc3-4733-8838-b7876b59e5a7", "env": {}}, "results": [{"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.735037Z", "completed_at": "2025-02-13T16:58:48.759642Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.760798Z", "completed_at": "2025-02-13T16:58:48.760812Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.04323410987854004, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__ace_project_grants", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='ace_project_grants')\n\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_excel(io.BytesIO(data), sheet_name='Project Grants Awards', engine=\"openpyxl\")\n    df.columns = df.iloc[1, :]\n    df = df.iloc[2:, :]\n    df.columns = [x.lower().replace(' ','_') for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__ace_project_grants\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__ace_project_grants\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__ace_project_grants\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.719227Z", "completed_at": "2025-02-13T16:58:48.760254Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.762558Z", "completed_at": "2025-02-13T16:58:48.762568Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.04767322540283203, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__ace_levelling_up_for_culture_places", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='ace_levelling_up_for_culture_places')\n\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_csv(io.BytesIO(data))\n    df.columns = [x.lower() for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__ace_levelling_up_for_culture_places\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__ace_levelling_up_for_culture_places\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__ace_levelling_up_for_culture_places\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.753604Z", "completed_at": "2025-02-13T16:58:48.761600Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.763886Z", "completed_at": "2025-02-13T16:58:48.763894Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.0473325252532959, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__ace_priority_places", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='ace_priority_places')\n\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_csv(io.BytesIO(data))\n    df.columns = [x.lower() for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__ace_priority_places\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__ace_priority_places\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__ace_priority_places\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.756329Z", "completed_at": "2025-02-13T16:58:48.762055Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.764616Z", "completed_at": "2025-02-13T16:58:48.764625Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.04861760139465332, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__ace_npo_funding", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='ace_npo_funding')\n\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_excel(io.BytesIO(data), sheet_name='data', engine=\"openpyxl\")\n    df.columns = [x.lower().replace(' ','_').replace('\\n', '_').replace('/','_').replace('(','_').replace(')','_') for x in df.columns]\n    df = df.rename(columns={\n        \"2018-22_average_annual_funding__figure_accurate_at_april_2018_\": \"average_annual_funding_2018_22\",\n        \"2022_23_annual_funding__extension_year_\": \"annual_funding__extension_year_2022_23\",\n        \"2023-26_annual_funding__offered_4_nov_2022_\": \"annual_funding__offered_4_nov_2022_2023_26\",\n    })\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__ace_npo_funding\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__ace_npo_funding\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__ace_npo_funding\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.770215Z", "completed_at": "2025-02-13T16:58:48.782654Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.784128Z", "completed_at": "2025-02-13T16:58:48.784138Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.018259763717651367, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__census", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef get_geography_from_filename(filename: str) -> str:\n    return filename.split('.')[0].split('-')[2]\n\n\ndef process_age_data(age_data: pd.DataFrame) -> pd.DataFrame:\n    column_groups = {\n        'Age: Age 16-19': ['Age: Aged 16 to 19 years; measures: Value'],\n        'Age: Age 20-24': ['Age: Aged 20 to 24 years; measures: Value'],\n        'Age: Age 25-29': [\n            'Age: Aged 25 years; measures: Value',\n            'Age: Aged 26 years; measures: Value',\n            'Age: Aged 27 years; measures: Value',\n            'Age: Aged 28 years; measures: Value',\n            'Age: Aged 29 years; measures: Value'\n        ],\n        'Age: Age 30-34': [\n            'Age: Aged 30 years; measures: Value',\n            'Age: Aged 31 years; measures: Value',\n            'Age: Aged 32 years; measures: Value',\n            'Age: Aged 33 years; measures: Value',\n            'Age: Aged 34 years; measures: Value'\n        ],\n        'Age: Age 35-39': [\n            'Age: Aged 35 years; measures: Value',\n            'Age: Aged 36 years; measures: Value',\n            'Age: Aged 37 years; measures: Value',\n            'Age: Aged 38 years; measures: Value',\n            'Age: Aged 39 years; measures: Value'\n        ],\n        'Age: Age 40-44': [\n            'Age: Aged 40 years; measures: Value',\n            'Age: Aged 41 years; measures: Value',\n            'Age: Aged 42 years; measures: Value',\n            'Age: Aged 43 years; measures: Value',\n            'Age: Aged 44 years; measures: Value'\n        ],\n        'Age: Age 45-49': [\n            'Age: Aged 45 years; measures: Value',\n            'Age: Aged 46 years; measures: Value',\n            'Age: Aged 47 years; measures: Value',\n            'Age: Aged 48 years; measures: Value',\n            'Age: Aged 49 years; measures: Value'\n        ],\n        'Age: Age 50-54': [\n            'Age: Aged 50 years; measures: Value',\n            'Age: Aged 51 years; measures: Value',\n            'Age: Aged 52 years; measures: Value',\n            'Age: Aged 53 years; measures: Value',\n            'Age: Aged 54 years; measures: Value'\n        ],\n        'Age: Age 55-59': [\n            'Age: Aged 55 years; measures: Value',\n            'Age: Aged 56 years; measures: Value',\n            'Age: Aged 57 years; measures: Value',\n            'Age: Aged 58 years; measures: Value',\n            'Age: Aged 59 years; measures: Value'\n        ],\n        'Age: Age 60-64': [\n            'Age: Aged 60 years; measures: Value',\n            'Age: Aged 61 years; measures: Value',\n            'Age: Aged 62 years; measures: Value',\n            'Age: Aged 63 years; measures: Value',\n            'Age: Aged 64 years; measures: Value'\n        ],\n        'Age: Age 65-69': [\n            'Age: Aged 65 years; measures: Value',\n            'Age: Aged 66 years; measures: Value',\n            'Age: Aged 67 years; measures: Value',\n            'Age: Aged 68 years; measures: Value',\n            'Age: Aged 69 years; measures: Value'\n        ],\n        'Age: Age 70-74': [\n            'Age: Aged 70 years; measures: Value',\n            'Age: Aged 71 years; measures: Value',\n            'Age: Aged 72 years; measures: Value',\n            'Age: Aged 73 years; measures: Value',\n            'Age: Aged 74 years; measures: Value'\n        ],\n        'Age: Age 75-79': [\n            'Age: Aged 75 years; measures: Value',\n            'Age: Aged 76 years; measures: Value',\n            'Age: Aged 77 years; measures: Value',\n            'Age: Aged 78 years; measures: Value',\n            'Age: Aged 79 years; measures: Value'\n        ],\n        'Age: Age 80-84': [\n            'Age: Aged 80 years; measures: Value',\n            'Age: Aged 81 years; measures: Value',\n            'Age: Aged 82 years; measures: Value',\n            'Age: Aged 83 years; measures: Value',\n            'Age: Aged 84 years; measures: Value'\n        ],\n        'Age: Age 85 and over': ['Age: Aged 85 years and over; measures: Value']\n        \n    }\n\n    df = age_data.copy()\n    for new_col, existing_columns in column_groups.items():\n        df[new_col] = df[existing_columns].sum(axis=1)\n\n    final_columns = ['date','geography','geography code','Age: Total; measures: Value'] + list(column_groups.keys())\n    df = df[final_columns]\n\n    return df\n\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='census')\n\n    frames = []\n    for blob in blobs:\n        if not blob.name.endswith('.csv'):\n            continue\n\n        geography = get_geography_from_filename(blob.name)    \n        if 'msoa' not in blob.name: # Only process MSOA data\n            continue\n            \n        try:\n            data = blob.download_as_bytes()\n            df = pd.read_csv(io.BytesIO(data))\n        except pd.errors.EmptyDataError as e:\n            continue\n\n        # If age data then preprocess\n        if 'ts007' in blob.name:\n            df = process_age_data(df)\n\n        total_column = [col for col in df.columns if 'Total' in col or 'All persons' in col][0] # Get total column\n        data_content = total_column.split(':')[0] # Get data content from column\n        value_columns = [col for col in df.columns if col not in ['date', 'geography', 'geography code', total_column]] # Get value columns\n\n        df_totals = df[['date', 'geography', 'geography code', total_column]].drop_duplicates()\n        df_values = df[['geography code'] + value_columns]\n        df_values = df_values.melt(\n            id_vars='geography code',\n            var_name='measure',\n            value_name='count'\n        )\n\n        df = df_totals.merge(df_values, how='left', on='geography code')\n        df = df.rename(columns={total_column: 'n', 'date': 'year'})\n\n        df['content'] = data_content\n        df['geography'] = geography\n        df = df[df['measure']!=total_column]\n        df['measure'] = df['measure'].apply(lambda x: (':').join(x.split(':')[1:]))\n        frames.append(df)\n\n    df = pd.concat(frames)\n    df.columns = [x.lower().replace(' ','_') for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__census\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__census\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__census\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.780030Z", "completed_at": "2025-02-13T16:58:48.783529Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.785786Z", "completed_at": "2025-02-13T16:58:48.785795Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.016631126403808594, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__grant360", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='grant360')\n\n    frames = []\n    for blob in blobs:\n        data = blob.download_as_bytes()\n        df = pd.read_csv(io.BytesIO(data))\n        df.columns = [x.lower().replace(' ', '_').replace('(', '').replace(')', '').replace(':', '_') for x in df.columns]\n        frames.append(df)\n    df = pd.concat(frames)\n    \n    df['award_date'] = df['award_date'].astype(str)\n    df['award_date'] = df['award_date'].apply(lambda x: x.replace('/', '-'))\n    df['award_date'] = df['award_date'].apply(lambda x: pd.to_datetime(x).strftime('%Y-%m-%d'))\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__grant360\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__grant360\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__grant360\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.773861Z", "completed_at": "2025-02-13T16:58:48.784822Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.787071Z", "completed_at": "2025-02-13T16:58:48.787078Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.019440889358520508, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__cultural_infrastructure", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='services')\n\n    frames = []\n    for blob in blobs:\n        data = blob.download_as_bytes()\n        df = pd.read_csv(io.BytesIO(data))\n        df.columns = [x.lower().replace(' ', '_').replace('(', '').replace(')', '').replace(':', '_') for x in df.columns]\n        frames.append(df)\n    df = pd.concat(frames)\n    df = df.drop('amount_awarded', axis=1)\n    df['postcode'] = df['postcode'].apply(lambda x: x.replace(' ', ''))\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__cultural_infrastructure\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__cultural_infrastructure\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__cultural_infrastructure\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.777400Z", "completed_at": "2025-02-13T16:58:48.785334Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.787786Z", "completed_at": "2025-02-13T16:58:48.787794Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.019147396087646484, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__economic", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport numpy as np\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef filter_columns(df: pd.DataFrame):\n    column_indices = [0]\n    i = 0\n    while i < len(df.columns):\n        if i + 3 < len(df.columns):\n            column_indices.extend([i + 3, i + 4])\n        i += 4\n\n    df = df.iloc[:, column_indices]\n    return df\n\n\n\ndef model(dbt, session):\n    \n    pd.set_option('future.no_silent_downcasting', True)\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='economic')\n\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n    df = pd.read_csv(io.BytesIO(data))\n\n    df.columns = df.loc[5,:]\n    df = df.loc[7:, :]\n    df = filter_columns(df)\n\n    new_columns = []\n    new_columns.append(df.columns[0])\n    i = 1\n    while i < len(df.columns):\n        if i + 1 < len(df.columns):\n            new_columns.append(df.columns[i] + ' - Value')\n            new_columns.append(df.columns[i] + ' - Margin of Error')\n        i += 2\n    df.columns = new_columns\n\n    df = df.replace(['#', '-', '!', '*', '~'], np.nan)\n    df = df.dropna(how='all')\n\n    local_authority_col = 'local authority: district / unitary (as of April 2021)'\n\n    # Identify value and margin columns\n    value_columns = [col for col in df.columns if 'Value' in col]\n\n    # Create a mapping from 'Value' columns to their corresponding 'Margin of Error' columns\n    value_to_margin_map = {\n        value_col: value_col.replace('Value', 'Margin of Error')\n        for value_col in value_columns\n    }\n\n    # Prepare an empty DataFrame to store the melted data\n    melted_df = pd.DataFrame()\n\n    # Melt the DataFrame for each pair of value and margin columns\n    for value_col, margin_col in value_to_margin_map.items():\n        temp_df = df[[local_authority_col, value_col, margin_col]].copy()\n        temp_df.columns = ['local authority', 'value', 'margin of error']\n        temp_df['measure'] = value_col.replace(' - Value', '')\n        melted_df = pd.concat([melted_df, temp_df], ignore_index=True)\n\n    melted_df = melted_df.reset_index(names='ID')\n    melted_df = melted_df[['ID', 'local authority', 'measure', 'value', 'margin of error']]\n    melted_df['value'] = melted_df['value'].apply(lambda x: float(x) / 100)\n    melted_df['margin of error'] = melted_df['margin of error'].apply(lambda x: float(x) / 100)\n    melted_df.columns = [x.lower().replace(' ','_') for x in melted_df.columns]\n\n    return melted_df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__economic\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__economic\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__economic\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.793166Z", "completed_at": "2025-02-13T16:58:48.804757Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.806185Z", "completed_at": "2025-02-13T16:58:48.806193Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.01721501350402832, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__indices_of_deprivation", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='indices_of_deprivation')\n    \n    for blob in blobs:\n        if blob.name.endswith('.csv'):\n            data = blob.download_as_bytes()\n    df = pd.read_csv(io.BytesIO(data))\n    df.columns = [x.lower().replace(' ', '_') for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__indices_of_deprivation\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__indices_of_deprivation\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__indices_of_deprivation\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.796845Z", "completed_at": "2025-02-13T16:58:48.805607Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.807883Z", "completed_at": "2025-02-13T16:58:48.807890Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.017361879348754883, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__msoa_mapping", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='msoa_mapping')\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_csv(io.BytesIO(data))\n    df.columns = [x.lower() for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__msoa_mapping\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__msoa_mapping\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__msoa_mapping\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.802202Z", "completed_at": "2025-02-13T16:58:48.806931Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.809281Z", "completed_at": "2025-02-13T16:58:48.809288Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.017185449600219727, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__postcode_mapping", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nimport numpy as np\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='postcode_mapping')\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_csv(io.BytesIO(data))\n    df = df.replace(r'^\\s*$', np.nan, regex=True)\n    df.columns = [x.lower() for x in df.columns]\n    df['pcd_no_space'] = df['pcd2'].apply(lambda x: x.replace(' ', ''))\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__postcode_mapping\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__postcode_mapping\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__postcode_mapping\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.799551Z", "completed_at": "2025-02-13T16:58:48.807410Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.809980Z", "completed_at": "2025-02-13T16:58:48.809987Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.018390655517578125, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__msoa_population", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='msoa_population')\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_excel(io.BytesIO(data), sheet_name='Mid-2021 MSOA 2021', engine='openpyxl')\n    df.columns = df.iloc[2, :]\n    df = df.iloc[3:, :]\n    df = df[['MSOA 2021 Code', 'Total']]\n    df.columns = [x.lower().replace(' ', '_') for x in df.columns]\n    df = df.rename(columns={'msoa_2021_code': 'msoa21cd', 'total': 'population'})\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__msoa_population\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__msoa_population\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__msoa_population\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.815470Z", "completed_at": "2025-02-13T16:58:48.826215Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.827573Z", "completed_at": "2025-02-13T16:58:48.827581Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.016347885131835938, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__rural_urban_classification", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nimport numpy as np\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='rural_urban_classification')\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    df = pd.read_csv(io.BytesIO(data))\n    df.columns = [x.lower() for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__rural_urban_classification\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__rural_urban_classification\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__rural_urban_classification\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.819087Z", "completed_at": "2025-02-13T16:58:48.826907Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.828824Z", "completed_at": "2025-02-13T16:58:48.828831Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.016053199768066406, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.raw__wellbeing", "compiled": true, "compiled_code": "import pandas as pd\nimport io\nimport os\nimport numpy as np\nfrom google.cloud import storage\nfrom dotenv import load_dotenv\n\n\ndef model(dbt, session):\n\n    pd.set_option('future.no_silent_downcasting', True)\n    load_dotenv('.env', override=True)\n    bucket_name = os.getenv('gcp_bucket')\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(bucket_name)\n    blobs = bucket.list_blobs(prefix='wellbeing')\n    blob = next(blobs, None)\n    data = blob.download_as_bytes()\n\n    sheets = {\n        '1 Life satisfaction means': 11,\n        '4 Worthwhile means': 11,\n        '7 Happiness means': 11,\n        '10 Anxiety means': 12\n    }\n\n    sheet_frames = []\n\n    for sheet, columns_row in sheets.items():\n\n        df = pd.read_excel(io.BytesIO(data), sheet_name=sheet, engine='openpyxl')\n        df.columns = df.iloc[columns_row,:]\n        df = df.iloc[columns_row+1:,1:]\n\n        df = df.replace('[cv1]', '<5%')\n        df = df.replace('[cv2]', '5-10%')\n        df = df.replace('[cv3]', '10-20%')\n        df = df.replace('[cv4]', '>20%')\n        df = df.replace('[u]', np.nan)\n        df = df.replace('[x]', np.nan)\n\n        index_column = 'Area Codes'\n\n        melted_df = pd.DataFrame()\n        i = 1\n        while i < len(df.columns):\n            value_column = df.columns[i]\n            error_column = df.columns[i+1]\n            temp_df = df[[index_column, value_column, error_column]].copy()\n            temp_df['date'] = value_column\n            temp_df.columns = ['area codes', 'value', 'margin of error', 'date']\n            melted_df = pd.concat([melted_df, temp_df], ignore_index=True)\n            i += 2\n\n        melted_df['wellbeing_factor'] = sheet\n        sheet_frames.append(melted_df)\n    df = pd.concat(sheet_frames)\n\n    df['wellbeing_factor'] = df['wellbeing_factor'].apply(lambda x: ' '.join(x.split(' ')[1:]))\n    df['value'] = df['value'].astype(float)\n    df = df.reset_index(names='ID')\n    df.columns = [x.lower().replace(' ','_') for x in df.columns]\n\n    return df\n\n\n# This part is user provided model code\n# you will need to copy the next section to run the code\n# COMMAND ----------\n# this part is dbt logic for get ref work, do not modify\n\ndef ref(*args, **kwargs):\n    refs = {}\n    key = '.'.join(args)\n    version = kwargs.get(\"v\") or kwargs.get(\"version\")\n    if version:\n        key += f\".v{version}\"\n    dbt_load_df_function = kwargs.get(\"dbt_load_df_function\")\n    return dbt_load_df_function(refs[key])\n\n\ndef source(*args, dbt_load_df_function):\n    sources = {}\n    key = '.'.join(args)\n    return dbt_load_df_function(sources[key])\n\n\nconfig_dict = {}\n\n\nclass config:\n    def __init__(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def get(key, default=None):\n        return config_dict.get(key, default)\n\nclass this:\n    \"\"\"dbt.this() or dbt.this.identifier\"\"\"\n    database = \"WMCSRP2\"\n    schema = \"md_raw\"\n    identifier = \"raw__wellbeing\"\n    \n    def __repr__(self):\n        return '\"WMCSRP2\".\"md_raw\".\"raw__wellbeing\"'\n\n\nclass dbtObj:\n    def __init__(self, load_df_function) -> None:\n        self.source = lambda *args: source(*args, dbt_load_df_function=load_df_function)\n        self.ref = lambda *args, **kwargs: ref(*args, **kwargs, dbt_load_df_function=load_df_function)\n        self.config = config\n        self.this = this()\n        self.is_incremental = False\n\n# COMMAND ----------\n\n\n", "relation_name": "\"WMCSRP2\".\"md_raw\".\"raw__wellbeing\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.821808Z", "completed_at": "2025-02-13T16:58:48.828334Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.830811Z", "completed_at": "2025-02-13T16:58:48.830817Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.016907930374145508, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.ace_levelling_up_for_culture_places", "compiled": true, "compiled_code": "select\n    *\nfrom\n    \"WMCSRP2\".\"md_raw\".\"raw__ace_levelling_up_for_culture_places\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"Arts Council England Levelling Up for Culture Places\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.824111Z", "completed_at": "2025-02-13T16:58:48.829732Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.832176Z", "completed_at": "2025-02-13T16:58:48.832183Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.017762422561645508, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.ace_priority_places", "compiled": true, "compiled_code": "select\n    *\nfrom\n    \"WMCSRP2\".\"md_raw\".\"raw__ace_priority_places\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"Arts Council England Priority Places\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.837337Z", "completed_at": "2025-02-13T16:58:48.841348Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.841822Z", "completed_at": "2025-02-13T16:58:48.841828Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.00841379165649414, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__rural_urban_classification", "compiled": true, "compiled_code": "with\n\nruc as (\n    select * from \"WMCSRP2\".\"md_raw\".\"raw__rural_urban_classification\"\n),\n\nmsoa_mapping as (\n    select * from \"WMCSRP2\".\"md_raw\".\"raw__msoa_mapping\"\n),\n\ncombined as (\n    select\n        ruc.msoa11cd,\n        ruc.msoa11nm,\n        ruc11cd,\n        ruc11\n    from ruc\n    left join msoa_mapping\n    on ruc.msoa11cd = msoa_mapping.msoa11cd\n)\n\nselect * from combined", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__rural_urban_classification\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.835047Z", "completed_at": "2025-02-13T16:58:48.843227Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.844167Z", "completed_at": "2025-02-13T16:58:48.844174Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.011377096176147461, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__area_codes", "compiled": true, "compiled_code": "with\n\ntarget_areas as (\n    select\n        case\n            when lad22nm in (\n                'Birmingham',\n                'Coventry',\n                'Dudley',\n                'Sandwell',\n                'Solihull',\n                'Walsall',\n                'Wolverhampton'\n            ) then 'WMCA Constituent Member'\n            when lad22nm in (\n                'Cannock Chase',\n                'North Warwickshire',\n                'Nuneaton and Bedworth',\n                'Redditch',\n                'Rugby',\n                'Shropshire',\n                'Stratford-on-Avon',\n                'Tamworth',\n                'Telford and Wrekin',\n                'Warwick'\n            ) then 'WMCA Non-Constituent Member'\n            when lad22nm in (\n                'Bromsgrove',\n                'East Staffordshire',\n                'Herefordshire, County of',\n                'Lichfield',\n                'Malvern Hills',\n                'Newcastle-under-Lyme',\n                'South Staffordshire',\n                'Stafford',\n                'Staffordshire Moorlands',\n                'Stoke-on-Trent',\n                'Worcester',\n                'Wychavon',\n                'Wyre Forest'\n            ) then 'West Midlands Non-WMCA'\n            else 'Ignore'\n        end as area,\n        lad22cd,\n        lad22nm,\n        msoa21cd,\n        msoa21nm\n    from\n        \"WMCSRP2\".\"md_raw\".\"raw__msoa_mapping\"\n)\n\nselect * from target_areas where area != 'Ignore'", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.846149Z", "completed_at": "2025-02-13T16:58:48.850391Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.852336Z", "completed_at": "2025-02-13T16:58:48.852342Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.008761405944824219, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.rural_urban_classification", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__rural_urban_classification\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"Rural Urban Classification\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.853037Z", "completed_at": "2025-02-13T16:58:48.861734Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.863951Z", "completed_at": "2025-02-13T16:58:48.863957Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.015221118927001953, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.indices_of_deprivation", "compiled": true, "compiled_code": "select *\nfrom \"WMCSRP2\".\"md_raw\".\"raw__indices_of_deprivation\"\nwhere\n    msoa21cd in (\n        select msoa21cd from \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n    )", "relation_name": "\"WMCSRP2\".\"md_marts\".\"Indices of Deprivation\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.855985Z", "completed_at": "2025-02-13T16:58:48.862950Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.865150Z", "completed_at": "2025-02-13T16:58:48.865157Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.015372753143310547, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__ace_npo_funding_aggregated", "compiled": true, "compiled_code": "with npo_funding as (\n    select * from \"WMCSRP2\".\"md_raw\".\"raw__ace_npo_funding\"\n),\n\n\naggregated as (\n    select\n        sum(annual_funding__extension_year_2022_23) as sum_annual_funding_extension_year,\n        sum(annual_funding__offered_4_nov_2022_2023_26) as sum_annual_funding_2023_2026,\n        sum(average_annual_funding_2018_22) sum_average_annual_funding_2018_2022,\n        local_authority\n    from\n        npo_funding\n    group by\n        local_authority\n),\n\nmsoa_mapping as (\n    select\n        lad22cd,\n        lad22nm\n    from\n        \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n),\n\n\ncombined as (\n    select\n        distinct lad22cd,\n        lad22nm,\n        case\n            when sum_annual_funding_extension_year is null then 0\n            else sum_annual_funding_extension_year\n        end as sum_annual_funding_extension_year,\n        case\n            when sum_annual_funding_2023_2026 is null then 0\n            else sum_annual_funding_2023_2026\n        end as sum_annual_funding_2023_2026,\n        case\n            when sum_average_annual_funding_2018_2022 is null then 0\n            else sum_average_annual_funding_2018_2022\n        end as sum_average_annual_funding_2018_2022,\n    from msoa_mapping\n    left join aggregated on msoa_mapping.lad22nm = aggregated.local_authority\n)\n\n\nselect * from combined", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__ace_npo_funding_aggregated\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.859209Z", "completed_at": "2025-02-13T16:58:48.863481Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.865832Z", "completed_at": "2025-02-13T16:58:48.865839Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.014558076858520508, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__ace_project_grants_aggregated", "compiled": true, "compiled_code": "with\n\nproject_grants as (\n    select * from \"WMCSRP2\".\"md_raw\".\"raw__ace_project_grants\"\n),\n\n\naggregated as (\n    select\n        sum(award_amount) as sum_award_amount,\n        local_authority\n    from\n        project_grants\n    group by\n        local_authority\n),\n\n\nmsoa_mapping as (\n    select\n        lad22cd,\n        lad22nm,\n        msoa21cd\n    from\n        \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n),\n\n\ncombined as (\n    select\n        distinct lad22cd,\n        lad22nm,\n        case\n            when sum_award_amount is null then 0\n            else sum_award_amount\n        end as sum_award_amount\n    from msoa_mapping\n    left join aggregated on msoa_mapping.lad22nm = aggregated.local_authority\n)\n\n\nselect * from combined", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__ace_project_grants_aggregated\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.867096Z", "completed_at": "2025-02-13T16:58:48.872569Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.874485Z", "completed_at": "2025-02-13T16:58:48.874492Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.01223134994506836, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__census_msoa_base", "compiled": true, "compiled_code": "with\n\nwmca_area_codes as (\n    select\n        distinct msoa21cd,\n        msoa21nm\n    from\n        \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n),\n\nmsoa_census as (\n    select\n        wac.msoa21cd,\n        wac.msoa21nm,\n        t.content,\n        t.measure,\n        t.count as count,\n        t.n as n\n    from\n        \"WMCSRP2\".\"md_raw\".\"raw__census\" as t\n    inner join\n        wmca_area_codes as wac\n    on\n        wac.msoa21cd = t.geography_code\n)\n\nselect\n    msoa21cd,\n    msoa21nm,\n    content,\n    rtrim(trim(regexp_replace(measure, '[\\s;]*measures: Value$', '')), ';') as measure,\n    count,\n    n\nfrom\n    msoa_census", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__census_msoa_base\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.880420Z", "completed_at": "2025-02-13T16:58:48.884673Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.886686Z", "completed_at": "2025-02-13T16:58:48.886696Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.01467275619506836, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__grant360", "compiled": true, "compiled_code": "with\n\npostcodes as (\n    select\n        msoa21,\n        pcd_no_space as postcode\n    from\n        \"WMCSRP2\".\"md_raw\".\"raw__postcode_mapping\"\n),\n\n\narea_codes as (\n    select\n        lad22cd,\n        lad22nm,\n        msoa21cd,\n    from\n        \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n),\n\n\ngrant360 as (\n    select\n        amount_awarded,\n        award_date,\n        recipient_org_name,\n        replace(recipient_org_postal_code, ' ', '') as recipient_org_postal_code,\n        funding_org_name\n    from\n        \"WMCSRP2\".\"md_raw\".\"raw__grant360\"\n),\n\n\ncombined as (\n    select\n        distinct area_codes.msoa21cd,\n        area_codes.lad22cd,\n        area_codes.lad22nm,\n        grant360.amount_awarded,\n        grant360.award_date,\n        grant360.recipient_org_name,\n        grant360.recipient_org_postal_code,\n        grant360.funding_org_name\n    from grant360\n    join postcodes on grant360.recipient_org_postal_code = postcodes.postcode\n    join area_codes on area_codes.msoa21cd = postcodes.msoa21\n)\n\n\nselect * from combined", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__grant360\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.877892Z", "completed_at": "2025-02-13T16:58:48.884220Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.887424Z", "completed_at": "2025-02-13T16:58:48.887432Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.015958070755004883, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__economic", "compiled": true, "compiled_code": "with\n\neconomic_data as (\n    select\n        local_authority,\n        measure,\n        value,\n        margin_of_error\n    from\n        \"WMCSRP2\".\"md_raw\".\"raw__economic\"\n),\n\nwmca_area_codes as (\n    select\n        lad22cd,\n        lad22nm,\n    from\n        \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n)\n\nselect\n    distinct ac.lad22cd,\n    ac.lad22nm,\n    ed.measure,\n    round(ed.value, 5) as value,\n    case\n        when margin_of_error < 0.05 then '<5%'\n        when margin_of_error < 0.1 then '5-10%'\n        when margin_of_error < 0.2 then '10-20%'\n    end as margin_of_error\nfrom\n    economic_data as ed\ninner join\n    wmca_area_codes as ac\non\n    ed.local_authority = ac.lad22nm", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__economic\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.875181Z", "completed_at": "2025-02-13T16:58:48.886208Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.890684Z", "completed_at": "2025-02-13T16:58:48.890691Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.019968509674072266, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__cultural_infrastructure", "compiled": true, "compiled_code": "with\n\nlad_codes as (\n    select distinct lad22nm, lad22cd\n    from \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n),\n\nservices_msoa as (\n    select\n        area_name as ladnm,\n        msoa21,\n        postcode,\n        service_type,\n        name as service_name,\n        source,\n        category,\n    from \"WMCSRP2\".\"md_raw\".\"raw__cultural_infrastructure\" as ci\n    left join \"WMCSRP2\".\"md_raw\".\"raw__postcode_mapping\" as pm\n    on ci.postcode = pm.pcd_no_space\n),\n\nservices_lad as (\n    select\n        *\n    from services_msoa\n    join lad_codes on services_msoa.ladnm = lad_codes.lad22nm\n)\n\nselect * from services_lad", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__cultural_infrastructure\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.888099Z", "completed_at": "2025-02-13T16:58:48.894062Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.896213Z", "completed_at": "2025-02-13T16:58:48.896219Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.011100292205810547, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__wellbeing", "compiled": true, "compiled_code": "with\n\nwellbeing_data as (\n    select\n        area_codes,\n        wellbeing_factor,\n        value,\n        margin_of_error \n    from\n        \"WMCSRP2\".\"md_raw\".\"raw__wellbeing\"\n),\n\nwmca_area_codes as (\n    select\n        lad22cd,\n        lad22nm\n    from\n        \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"\n)\n\nselect\n    distinct ac.lad22cd,\n    ac.lad22nm,\n    wd.wellbeing_factor,\n    wd.value,\n    wd.margin_of_error,\nfrom\n    wmca_area_codes as ac\nleft join\n    wellbeing_data as wd\non\n    wd.area_codes = ac.lad22cd", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__wellbeing\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.897875Z", "completed_at": "2025-02-13T16:58:48.905934Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.907647Z", "completed_at": "2025-02-13T16:58:48.907653Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.0141448974609375, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.west_midlands_area_codes", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__area_codes\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"West Midlands Area Codes\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.903053Z", "completed_at": "2025-02-13T16:58:48.907145Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.913405Z", "completed_at": "2025-02-13T16:58:48.913412Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.018259286880493164, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.ace_project_grants_funding", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__ace_project_grants_aggregated\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"Arts Council England Project Grants Funding\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.900857Z", "completed_at": "2025-02-13T16:58:48.912882Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.914784Z", "completed_at": "2025-02-13T16:58:48.914791Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.020168781280517578, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.ace_npo_funding", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__ace_npo_funding_aggregated\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"Arts Council England NPO Funding\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.908427Z", "completed_at": "2025-02-13T16:58:48.915522Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.917641Z", "completed_at": "2025-02-13T16:58:48.917649Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.012309551239013672, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__census_msoa_with_population", "compiled": true, "compiled_code": "with msoa_census as (\n    select * from \"WMCSRP2\".\"md_warehouse\".\"int__census_msoa_base\"\n),\n\n\nmsoa_population as (\n    select * from \"WMCSRP2\".\"md_raw\".\"raw__msoa_population\"\n),\n\ncombined as (\n    select\n        msoa_census.msoa21cd,\n        msoa21nm,\n        content,\n        measure,\n        count,\n        n,\n        case\n            when n >= population then n+5\n            else population\n        end as population,\n    from msoa_census\n    join msoa_population on msoa_census.msoa21cd = msoa_population.msoa21cd\n)\n\nselect * from combined", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__census_msoa_with_population\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.920936Z", "completed_at": "2025-02-13T16:58:48.928754Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.929918Z", "completed_at": "2025-02-13T16:58:48.929925Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.013438224792480469, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.grant360_funding_data", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__grant360\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"Grant360 Funding Data\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.926476Z", "completed_at": "2025-02-13T16:58:48.933090Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.934771Z", "completed_at": "2025-02-13T16:58:48.934778Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.015532493591308594, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__cultural_infrastructure_lad", "compiled": true, "compiled_code": "with\n\ndistinct_services as (\n    select\n        distinct service_name,\n        lad22cd,\n        service_type\n    from \"WMCSRP2\".\"md_warehouse\".\"int__cultural_infrastructure\"\n)\n\nselect\n    lad22cd,\n    service_type,\n    count(service_name) as service_count\nfrom distinct_services\ngroup by lad22cd, service_type", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__cultural_infrastructure_lad\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.924170Z", "completed_at": "2025-02-13T16:58:48.933640Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.935552Z", "completed_at": "2025-02-13T16:58:48.935557Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.01728343963623047, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.annual_population_survey_economic_measures", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__economic\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"Annual Population Survey Economic Measures\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.930841Z", "completed_at": "2025-02-13T16:58:48.936240Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.937892Z", "completed_at": "2025-02-13T16:58:48.937898Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.014324426651000977, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__cultural_infrastructure_msoa", "compiled": true, "compiled_code": "with\n\ndistinct_services as (\n    select\n        distinct service_name,\n        msoa21,\n        service_type\n    from \"WMCSRP2\".\"md_warehouse\".\"int__cultural_infrastructure\"\n)\n\nselect\n    msoa21,\n    service_type,\n    count(service_name) as service_count\nfrom distinct_services\ngroup by msoa21, service_type", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__cultural_infrastructure_msoa\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.940340Z", "completed_at": "2025-02-13T16:58:48.946029Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.947131Z", "completed_at": "2025-02-13T16:58:48.947138Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.010512828826904297, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.annual_population_survey_welbeing_estimates", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__wellbeing\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"Annual Population Survey Wellbeing Estimates\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.943710Z", "completed_at": "2025-02-13T16:58:48.950095Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.950788Z", "completed_at": "2025-02-13T16:58:48.950794Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.011767387390136719, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.int__census_msoa_with_error", "compiled": true, "compiled_code": "with msoa_census as (\n    select * from \"WMCSRP2\".\"md_warehouse\".\"int__census_msoa_with_population\"\n),\n\n\nmsoa_errors as (\n    select\n        msoa21cd,\n        msoa21nm,\n        content as census_question,\n        measure as answer,\n        count as count_of_answer,\n        n as sample_size,\n        population as population_size,\n        count / n as p,\n        1.96 * sqrt( (p * (1-p)) / ((population - 1) * n / (population - n)) ) as margin_of_error\n    from\n        msoa_census\n)\n\n\nselect * from msoa_errors", "relation_name": "\"WMCSRP2\".\"md_warehouse\".\"int__census_msoa_with_error\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.947882Z", "completed_at": "2025-02-13T16:58:48.951711Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.952678Z", "completed_at": "2025-02-13T16:58:48.952685Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.009664058685302734, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.cultural_infrastructure", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__cultural_infrastructure_msoa\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"Cultural Infrastructure\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-02-13T16:58:48.954482Z", "completed_at": "2025-02-13T16:58:48.956645Z"}, {"name": "execute", "started_at": "2025-02-13T16:58:48.957071Z", "completed_at": "2025-02-13T16:58:48.957075Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.0037610530853271484, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.WMCSRP2_dataset.census", "compiled": true, "compiled_code": "select * from \"WMCSRP2\".\"md_warehouse\".\"int__census_msoa_with_error\"", "relation_name": "\"WMCSRP2\".\"md_marts\".\"Census 2021 Data\"", "batch_results": null}], "elapsed_time": 0.36415553092956543, "args": {"which": "generate", "cache_selected_only": false, "quiet": false, "compile": true, "log_format": "default", "skip_nodes_if_on_run_start_fails": false, "empty_catalog": false, "favor_state": false, "partial_parse_file_diff": true, "require_batched_execution_for_custom_microbatch_strategy": false, "show_resource_report": false, "state_modified_compare_vars": false, "exclude": [], "write_json": true, "log_level_file": "debug", "select": [], "printer_width": 80, "invocation_command": "dbt docs generate", "defer": false, "log_path": "/home/runner/work/wmcsrp-2/wmcsrp-2/logs", "partial_parse": true, "use_colors": true, "require_yaml_configuration_for_mf_time_spines": false, "source_freshness_run_project_hooks": false, "static": false, "macro_debugging": false, "require_resource_names_without_spaces": false, "send_anonymous_usage_stats": true, "state_modified_compare_more_unrendered_values": false, "project_dir": "/home/runner/work/wmcsrp-2/wmcsrp-2", "vars": {}, "log_file_max_bytes": 10485760, "introspect": true, "populate_cache": true, "require_explicit_package_overrides_for_builtin_materializations": true, "profiles_dir": "/home/runner/work/wmcsrp-2/wmcsrp-2", "static_parser": true, "version_check": true, "indirect_selection": "eager", "require_nested_cumulative_type_params": false, "print": true, "use_colors_file": true, "warn_error_options": {"include": [], "exclude": []}, "strict_mode": false, "log_format_file": "debug", "log_level": "info"}}